"""Automated penetration testing API endpoints."""

from __future__ import annotations

from typing import Any, Dict, List, MutableMapping, Optional

import structlog
from fastapi import APIRouter, Depends, HTTPException, status
from pydantic import BaseModel, Field
from src.api.dependencies import authenticate, authenticated_payload
from src.services.automated_pentest import get_automated_pentest_engine

logger = structlog.get_logger(__name__)

router = APIRouter(tags=["automated-pentest"])


class FindingInput(BaseModel):
    """Input model for a security finding."""

    id: Optional[str] = None
    rule_id: Optional[str] = None
    name: Optional[str] = None
    description: Optional[str] = None
    message: Optional[str] = None
    severity: str = "medium"
    cvss_score: Optional[float] = None
    cve_id: Optional[str] = None
    cwe_id: Optional[str] = None
    kev: bool = False
    epss: Optional[float] = None
    location: Optional[Dict[str, Any]] = None
    metadata: Optional[Dict[str, Any]] = None


class PenTestContext(BaseModel):
    """Context for penetration testing."""

    target_url: Optional[str] = None
    environment: str = "production"
    scope: Optional[Dict[str, Any]] = None
    credentials: Optional[Dict[str, str]] = None
    excluded_paths: List[str] = Field(default_factory=list)
    metadata: Optional[Dict[str, Any]] = None


class PenTestOptions(BaseModel):
    """Options for penetration testing."""

    run_validation: bool = True
    generate_narratives: bool = True
    include_compliance_mapping: bool = True
    max_findings: int = 100
    timeout_seconds: int = 3600


class RunPenTestRequest(BaseModel):
    """Request model for running a penetration test."""

    findings: List[FindingInput]
    context: PenTestContext = Field(default_factory=PenTestContext)
    options: PenTestOptions = Field(default_factory=PenTestOptions)


class AttackNarrativeRequest(BaseModel):
    """Request model for generating an attack narrative."""

    finding: FindingInput
    context: PenTestContext = Field(default_factory=PenTestContext)


class ValidateVulnerabilityRequest(BaseModel):
    """Request model for validating a vulnerability."""

    finding: FindingInput
    context: PenTestContext = Field(default_factory=PenTestContext)


@router.post("/run", response_model=dict)
async def run_automated_pentest(
    request: RunPenTestRequest,
    _: None = Depends(authenticate),
) -> MutableMapping[str, Any]:
    """
    Run a complete automated penetration test.

    This endpoint analyzes security findings, generates attack narratives,
    performs non-destructive validation checks, and produces a comprehensive
    penetration test report.

    The test includes:
    - Vulnerability categorization and analysis
    - Attack chain generation
    - Non-destructive validation (if enabled)
    - Attack narrative generation
    - Risk assessment and prioritization
    - Compliance mapping
    - Remediation recommendations
    """
    logger.info(
        "automated_pentest.run.start",
        findings_count=len(request.findings),
        run_validation=request.options.run_validation,
    )

    if len(request.findings) > request.options.max_findings:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Too many findings. Maximum allowed: {request.options.max_findings}",
        )

    if not request.findings:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="At least one finding is required",
        )

    try:
        engine = get_automated_pentest_engine()

        findings_dicts = [f.model_dump() for f in request.findings]
        context_dict = request.context.model_dump()
        options_dict = request.options.model_dump()

        report = await engine.run_pentest(
            findings=findings_dicts,
            context=context_dict,
            options=options_dict,
        )

        logger.info(
            "automated_pentest.run.completed",
            report_id=report.id,
            findings_processed=len(report.findings),
            duration_seconds=report.metadata.get("duration_seconds"),
        )

        return {
            "status": "completed",
            "report": {
                "id": report.id,
                "title": report.title,
                "executive_summary": report.executive_summary,
                "scope": report.scope,
                "methodology": report.methodology,
                "findings": report.findings,
                "risk_summary": report.risk_summary,
                "recommendations": report.recommendations,
                "compliance_mapping": report.compliance_mapping,
                "generated_at": report.generated_at.isoformat(),
                "metadata": report.metadata,
            },
            "attack_narratives": [
                {
                    "vulnerability_id": n.vulnerability_id,
                    "title": n.title,
                    "executive_summary": n.executive_summary,
                    "business_impact": n.business_impact,
                    "technical_impact": n.technical_impact,
                    "likelihood": n.likelihood,
                    "risk_rating": n.risk_rating,
                    "compliance_implications": n.compliance_implications,
                    "mitigations": n.mitigations,
                    "references": n.references,
                    "attack_vectors": [
                        {
                            "id": v.id,
                            "name": v.name,
                            "category": v.category.value,
                            "description": v.description,
                            "difficulty": v.difficulty.value,
                            "impact": v.impact,
                            "cvss_score": v.cvss_score,
                            "mitre_attack_ids": v.mitre_attack_ids,
                            "techniques": v.techniques,
                        }
                        for v in n.attack_vectors
                    ],
                    "attack_chain": [
                        {
                            "phase": s.phase.value,
                            "action": s.action,
                            "description": s.description,
                            "tool": s.tool,
                            "expected_output": s.expected_output,
                            "duration_estimate_seconds": s.duration_estimate_seconds,
                            "is_destructive": s.is_destructive,
                        }
                        for s in n.attack_chain
                    ],
                }
                for n in report.attack_narratives
            ],
            "validation_results": [
                {
                    "vulnerability_id": v.vulnerability_id,
                    "status": v.status.value,
                    "confidence": v.confidence,
                    "evidence": v.evidence,
                    "steps_executed": v.steps_executed,
                    "duration_seconds": v.duration_seconds,
                    "blocked_by": v.blocked_by,
                    "error": v.error,
                    "recommendations": v.recommendations,
                }
                for v in report.validation_results
            ],
        }

    except Exception as e:
        logger.exception("automated_pentest.run.error", error=str(e))
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Penetration test failed due to an internal error",
        )


@router.post("/narrative", response_model=dict)
async def generate_attack_narrative(
    request: AttackNarrativeRequest,
    _: None = Depends(authenticate),
) -> MutableMapping[str, Any]:
    """
    Generate an attack narrative for a single vulnerability.

    This endpoint creates a detailed attack narrative including:
    - Attack vectors and techniques
    - Multi-stage attack chain
    - Business and technical impact assessment
    - Risk rating and likelihood
    - Compliance implications
    - Mitigation recommendations
    """
    logger.info(
        "automated_pentest.narrative.start",
        finding_id=request.finding.id or request.finding.rule_id,
    )

    try:
        engine = get_automated_pentest_engine()

        finding_dict = request.finding.model_dump()
        context_dict = request.context.model_dump()

        narrative = engine.narrative_generator.generate_narrative(
            finding=finding_dict,
            context=context_dict,
        )

        logger.info(
            "automated_pentest.narrative.completed",
            vulnerability_id=narrative.vulnerability_id,
            risk_rating=narrative.risk_rating,
        )

        return {
            "status": "completed",
            "narrative": {
                "vulnerability_id": narrative.vulnerability_id,
                "title": narrative.title,
                "executive_summary": narrative.executive_summary,
                "business_impact": narrative.business_impact,
                "technical_impact": narrative.technical_impact,
                "likelihood": narrative.likelihood,
                "risk_rating": narrative.risk_rating,
                "compliance_implications": narrative.compliance_implications,
                "mitigations": narrative.mitigations,
                "references": narrative.references,
                "attack_vectors": [
                    {
                        "id": v.id,
                        "name": v.name,
                        "category": v.category.value,
                        "description": v.description,
                        "prerequisites": v.prerequisites,
                        "techniques": v.techniques,
                        "difficulty": v.difficulty.value,
                        "impact": v.impact,
                        "cvss_score": v.cvss_score,
                        "mitre_attack_ids": v.mitre_attack_ids,
                    }
                    for v in narrative.attack_vectors
                ],
                "attack_chain": [
                    {
                        "phase": s.phase.value,
                        "action": s.action,
                        "description": s.description,
                        "tool": s.tool,
                        "expected_output": s.expected_output,
                        "success_indicators": s.success_indicators,
                        "failure_indicators": s.failure_indicators,
                        "duration_estimate_seconds": s.duration_estimate_seconds,
                        "is_destructive": s.is_destructive,
                    }
                    for s in narrative.attack_chain
                ],
            },
        }

    except Exception as e:
        logger.exception("automated_pentest.narrative.error", error=str(e))
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Narrative generation failed due to an internal error",
        )


@router.post("/validate", response_model=dict)
async def validate_vulnerability(
    request: ValidateVulnerabilityRequest,
    _: None = Depends(authenticate),
) -> MutableMapping[str, Any]:
    """
    Validate a single vulnerability using non-destructive checks.

    This endpoint performs security validation to determine if a
    vulnerability is actually exploitable. All checks are non-destructive
    and safe to run against production systems.

    Returns:
    - Validation status (confirmed, likely, possible, false_positive, blocked)
    - Confidence score
    - Evidence collected
    - Steps executed
    - Recommendations
    """
    logger.info(
        "automated_pentest.validate.start",
        finding_id=request.finding.id or request.finding.rule_id,
    )

    try:
        engine = get_automated_pentest_engine()

        finding_dict = request.finding.model_dump()
        context_dict = request.context.model_dump()

        vector = engine.analyzer.generate_attack_vector(finding_dict)
        attack_chain = engine.chain_generator.generate_attack_chain(
            vector, context_dict
        )

        result = await engine.validator.validate_vulnerability(
            finding=finding_dict,
            context=context_dict,
            attack_chain=attack_chain,
        )

        logger.info(
            "automated_pentest.validate.completed",
            vulnerability_id=result.vulnerability_id,
            status=result.status.value,
            confidence=result.confidence,
        )

        return {
            "status": "completed",
            "validation": {
                "vulnerability_id": result.vulnerability_id,
                "status": result.status.value,
                "confidence": result.confidence,
                "evidence": result.evidence,
                "steps_executed": result.steps_executed,
                "duration_seconds": result.duration_seconds,
                "blocked_by": result.blocked_by,
                "error": result.error,
                "recommendations": result.recommendations,
            },
        }

    except Exception as e:
        logger.exception("automated_pentest.validate.error", error=str(e))
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Validation failed due to an internal error",
        )


@router.post("/analyze", response_model=dict)
async def analyze_findings(
    payload: Dict[str, Any] = Depends(authenticated_payload),
    _: None = Depends(authenticate),
) -> MutableMapping[str, Any]:
    """
    Analyze security findings and categorize them.

    This endpoint takes raw findings (SARIF, JSON, or list format) and
    returns categorized vulnerabilities with attack vectors.
    """
    findings = payload.get("findings", [])

    if isinstance(findings, dict):
        runs = findings.get("runs", [])
        extracted_findings = []
        for run in runs:
            for result in run.get("results", []):
                extracted_findings.append(
                    {
                        "id": result.get("ruleId"),
                        "rule_id": result.get("ruleId"),
                        "message": result.get("message", {}).get("text", ""),
                        "severity": _sarif_level_to_severity(
                            result.get("level", "warning")
                        ),
                        "location": result.get("locations", [{}])[0]
                        if result.get("locations")
                        else {},
                    }
                )
        findings = extracted_findings

    if not findings:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="No findings provided",
        )

    logger.info("automated_pentest.analyze.start", findings_count=len(findings))

    try:
        engine = get_automated_pentest_engine()

        analyzed = []
        for finding in findings:
            vector = engine.analyzer.generate_attack_vector(finding)
            analyzed.append(
                {
                    "finding_id": finding.get("id", finding.get("rule_id", "unknown")),
                    "original_severity": finding.get("severity", "medium"),
                    "category": vector.category.value,
                    "difficulty": vector.difficulty.value,
                    "cvss_score": vector.cvss_score,
                    "mitre_attack_ids": vector.mitre_attack_ids,
                    "techniques": vector.techniques,
                    "prerequisites": vector.prerequisites,
                }
            )

        category_summary = {}
        for item in analyzed:
            cat = item["category"]
            if cat not in category_summary:
                category_summary[cat] = 0
            category_summary[cat] += 1

        logger.info(
            "automated_pentest.analyze.completed",
            findings_analyzed=len(analyzed),
        )

        return {
            "status": "completed",
            "analyzed_findings": analyzed,
            "category_summary": category_summary,
            "total_findings": len(analyzed),
        }

    except Exception as e:
        logger.exception("automated_pentest.analyze.error", error=str(e))
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Analysis failed due to an internal error",
        )


@router.get("/categories", response_model=dict)
async def list_vulnerability_categories(
    _: None = Depends(authenticate),
) -> MutableMapping[str, Any]:
    """
    List all supported vulnerability categories.

    Returns the vulnerability categories supported by the automated
    penetration testing engine, along with their descriptions and
    MITRE ATT&CK mappings.
    """
    from src.services.automated_pentest import (
        VulnerabilityAnalyzer,
        VulnerabilityCategory,
    )

    analyzer = VulnerabilityAnalyzer()

    categories = []
    for category in VulnerabilityCategory:
        categories.append(
            {
                "id": category.value,
                "name": category.value.replace("_", " ").title(),
                "mitre_attack_ids": analyzer.MITRE_ATTACK_MAPPING.get(category, []),
            }
        )

    return {
        "categories": categories,
        "total": len(categories),
    }


@router.get("/attack-phases", response_model=dict)
async def list_attack_phases(
    _: None = Depends(authenticate),
) -> MutableMapping[str, Any]:
    """
    List all attack phases in the penetration testing methodology.

    Returns the phases of a penetration test as implemented by the
    automated testing engine.
    """
    from src.services.automated_pentest import AttackPhase

    phases = [
        {
            "id": phase.value,
            "name": phase.value.replace("_", " ").title(),
            "order": i + 1,
        }
        for i, phase in enumerate(AttackPhase)
    ]

    return {
        "phases": phases,
        "total": len(phases),
    }


def _sarif_level_to_severity(level: str) -> str:
    """Convert SARIF level to severity string."""
    level_map = {
        "error": "critical",
        "warning": "high",
        "note": "medium",
        "none": "low",
    }
    return level_map.get(level.lower(), "medium")


__all__ = ["router"]
