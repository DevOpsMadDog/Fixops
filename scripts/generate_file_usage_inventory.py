"""Generate file usage inventory with heuristic classifications.

This module scans the Git repository and produces three artefacts under
``analysis/``:

* ``file_usage_summary.csv`` – per-file line counts with usage status
* ``file_usage_totals.json`` – aggregate counts grouped by status
* ``file_usage_report.md`` – human readable overview with highlights

The heuristics are intentionally transparent: the script records the rule and
reason that determined each classification so reviewers can challenge or amend
it. Override entries in ``analysis/file_usage_overrides.json`` take precedence
when present. The override file accepts a JSON object of the following shape:

```
{
  "overrides": {
    "relative/path.py": {
      "status": "not_needed",
      "category": "generated",
      "reason": "Generated artefact; regenerate on demand"
    }
  }
}
```
"""
from __future__ import annotations

import csv
import fnmatch
import json
import subprocess
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Tuple

REPO_ROOT = Path(__file__).resolve().parents[1]
ANALYSIS_DIR = REPO_ROOT / "analysis"
SUMMARY_PATH = ANALYSIS_DIR / "file_usage_summary.csv"
TOTALS_PATH = ANALYSIS_DIR / "file_usage_totals.json"
REPORT_PATH = ANALYSIS_DIR / "file_usage_report.md"
OVERRIDES_PATH = ANALYSIS_DIR / "file_usage_overrides.json"


@dataclass
class Rule:
    patterns: Tuple[str, ...]
    status: str
    category: str
    reason: str

    def matches(self, path: str) -> bool:
        return any(fnmatch.fnmatch(path, pattern) for pattern in self.patterns)


DEFAULT_RULES: Tuple[Rule, ...] = (
    Rule(
        patterns=(
            "analysis/file_usage_summary.csv",
            "analysis/file_usage_totals.json",
            "analysis/file_usage_report.md",
            "analysis/file_usage_overrides.json",
        ),
        status="not_needed",
        category="generated-inventory",
        reason="Inventory artefact generated by scripts/generate_file_usage_inventory.py; regenerate when required.",
    ),
    Rule(
        patterns=("analysis/*",),
        status="supporting",
        category="analysis",
        reason="Analytical documentation and reports referenced during audits.",
    ),
    Rule(
        patterns=("simulations/**", "demo/**"),
        status="not_needed",
        category="demo-fixture",
        reason="Sample/demo data for simulations; omit in production deployments.",
    ),
    Rule(
        patterns=("tests/**",),
        status="needed",
        category="tests",
        reason="Automated regression coverage for the platform.",
    ),
    Rule(
        patterns=("docs/**", "*.md", "*.rst"),
        status="supporting",
        category="documentation",
        reason="Human-facing documentation that accelerates onboarding and reviews.",
    ),
    Rule(
        patterns=("fixops-enterprise/**", "apps/**", "core/**", "backend/**", "enterprise/**", "integrations/**"),
        status="needed",
        category="core",
        reason="Core product implementation files.",
    ),
    Rule(
        patterns=("scripts/**", "Makefile", "requirements*.txt"),
        status="needed",
        category="tooling",
        reason="Tooling required to execute workflows and pipelines.",
    ),
    Rule(
        patterns=("marketplace/**",),
        status="needed",
        category="marketplace",
        reason="Marketplace metadata served by new API endpoints.",
    ),
    Rule(
        patterns=("fastapi/**", "pydantic/**", "pydantic_settings/**"),
        status="needed",
        category="vendor-shims",
        reason="In-repo shims replacing third-party packages in restricted environments.",
    ),
)


@dataclass
class InventoryEntry:
    path: str
    lines: int
    status: str
    category: str
    reason: str
    rule_source: str


def git_tracked_files() -> List[str]:
    result = subprocess.run(
        ["git", "ls-files"],
        cwd=REPO_ROOT,
        check=True,
        capture_output=True,
        text=True,
    )
    return [line.strip() for line in result.stdout.splitlines() if line.strip()]


def count_lines(path: Path) -> int:
    try:
        with path.open("rb") as handle:
            return sum(1 for _ in handle)
    except FileNotFoundError:
        return 0


def load_overrides() -> Dict[str, Dict[str, str]]:
    if not OVERRIDES_PATH.exists():
        return {}
    try:
        data = json.loads(OVERRIDES_PATH.read_text(encoding="utf-8"))
    except json.JSONDecodeError as exc:
        raise RuntimeError(f"Invalid JSON in {OVERRIDES_PATH}: {exc}") from exc
    overrides = data.get("overrides", {})
    return {str(path): details for path, details in overrides.items()}


def classify(path: str, overrides: Dict[str, Dict[str, str]]) -> InventoryEntry:
    override = overrides.get(path)
    if override:
        status = override.get("status", "supporting")
        category = override.get("category", "override")
        reason = override.get("reason", "Marked via override file.")
        rule_source = "override"
    else:
        matching_rule: Optional[Rule] = next((rule for rule in DEFAULT_RULES if rule.matches(path)), None)
        if matching_rule:
            status = matching_rule.status
            category = matching_rule.category
            reason = matching_rule.reason
            rule_source = "heuristic"
        else:
            status = "supporting"
            category = "misc"
            reason = "No specific rule matched; defaulting to supporting."
            rule_source = "default"
    lines = count_lines(REPO_ROOT / path)
    return InventoryEntry(path=path, lines=lines, status=status, category=category, reason=reason, rule_source=rule_source)


def write_summary(entries: Iterable[InventoryEntry]) -> None:
    ANALYSIS_DIR.mkdir(exist_ok=True)
    with SUMMARY_PATH.open("w", newline="", encoding="utf-8") as handle:
        writer = csv.writer(handle)
        writer.writerow(["file", "lines", "status", "category", "reason", "source"])
        for entry in entries:
            writer.writerow([entry.path, entry.lines, entry.status, entry.category, entry.reason, entry.rule_source])


def write_totals(entries: Iterable[InventoryEntry]) -> None:
    totals: Dict[str, Dict[str, int]] = {}
    for entry in entries:
        status_bucket = totals.setdefault(entry.status, {"files": 0, "lines": 0})
        status_bucket["files"] += 1
        status_bucket["lines"] += entry.lines
    TOTALS_PATH.write_text(json.dumps({"by_status": totals}, indent=2) + "\n", encoding="utf-8")


def write_report(entries: Iterable[InventoryEntry]) -> None:
    totals = json.loads(TOTALS_PATH.read_text(encoding="utf-8"))
    needed = totals["by_status"].get("needed", {"files": 0, "lines": 0})
    supporting = totals["by_status"].get("supporting", {"files": 0, "lines": 0})
    optional = totals["by_status"].get("not_needed", {"files": 0, "lines": 0})

    REPORT_PATH.write_text(
        "\n".join(
            [
                "# Repository File Usage Inventory",
                "",
                "This report is generated automatically by ``scripts/generate_file_usage_inventory.py``.",
                "",
                "## Totals by status",
                "",
                "| Status | Files | Lines |",
                "| --- | ---: | ---: |",
                f"| needed | {needed['files']} | {needed['lines']} |",
                f"| supporting | {supporting['files']} | {supporting['lines']} |",
                f"| not_needed | {optional['files']} | {optional['lines']} |",
                "",
                "Statuses marked **not_needed** are safe to exclude from the production-critical deployment",
                "because they either represent generated artefacts or demo fixtures. Supporting files are kept",
                "to maintain documentation and analysis quality but can be reviewed if footprint reductions",
                "are required.",
                "",
                "Detailed entries live in ``analysis/file_usage_summary.csv`` with columns for the rule",
                "source and rationale behind each classification. Adjust ``analysis/file_usage_overrides.json``",
                "to enforce custom decisions.",
            ]
        )
        + "\n",
        encoding="utf-8",
    )


def main() -> None:
    overrides = load_overrides()
    entries = [classify(path, overrides) for path in git_tracked_files()]
    write_summary(entries)
    write_totals(entries)
    write_report(entries)


if __name__ == "__main__":
    main()
