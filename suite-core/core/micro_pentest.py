"""Core micro penetration test functionality with AI-powered analysis.

This module provides the shared business logic for micropentests, used by both
the main API router and the enterprise API router.

Architecture (PentAGI-based):
- Deterministic Scanner: 4-stage verification pipeline + 19-phase general scan
- AI Orchestration Layer: MultiAIOrchestrator with 3 LLM providers in consensus
  • Gemini  → Solution Architect (attack surface, business impact)
  • Claude  → Developer (exploitability, tools, payload design)
  • GPT-4   → Team Lead (strategy, risk assessment, success criteria)
- Intelligent Exploit Generator: LLM-driven payload generation & optimization
- Consensus weights: architect=0.35, developer=0.40, lead=0.25
"""

from __future__ import annotations

import asyncio
import os
import re
import time
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional
from urllib.parse import urlparse

import httpx
import structlog

logger = structlog.get_logger(__name__)

# Maximum context size to prevent accidentally sending large payloads
MAX_CONTEXT_SIZE = 10000  # 10KB limit

# CVE ID pattern for validation
CVE_PATTERN = re.compile(r"^CVE-\d{4}-\d{4,}$", re.IGNORECASE)

# Allowed URL schemes for target URLs
ALLOWED_URL_SCHEMES = {"http", "https"}


def _validate_cve_id(cve_id: str) -> bool:
    """Validate CVE ID format to prevent prompt injection."""
    return bool(CVE_PATTERN.match(cve_id))


def _validate_target_url(url: str) -> bool:
    """Validate target URL to prevent SSRF attacks.

    Only allows http/https schemes and rejects internal/private IPs.
    """
    try:
        parsed = urlparse(url)
        if parsed.scheme not in ALLOWED_URL_SCHEMES:
            return False
        if not parsed.netloc:
            return False
        # Block localhost and common internal hostnames
        hostname = parsed.hostname or ""
        if hostname in ("localhost", "127.0.0.1", "0.0.0.0", "::1"):
            return False
        # Block private IP ranges (basic check)
        if hostname.startswith(
            (
                "10.",
                "192.168.",
                "172.16.",
                "172.17.",
                "172.18.",
                "172.19.",
                "172.20.",
                "172.21.",
                "172.22.",
                "172.23.",
                "172.24.",
                "172.25.",
                "172.26.",
                "172.27.",
                "172.28.",
                "172.29.",
                "172.30.",
                "172.31.",
            )
        ):
            return False
        return True
    except Exception:
        return False


def _sanitize_context(context: Optional[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
    """Validate and sanitize context to prevent oversized payloads."""
    if context is None:
        return None
    import json

    try:
        serialized = json.dumps(context)
        if len(serialized) > MAX_CONTEXT_SIZE:
            logger.warning(
                f"micro_pentest.context_too_large size={len(serialized)} max_size={MAX_CONTEXT_SIZE}"
            )
            return {
                "error": "Context too large, truncated",
                "original_size": len(serialized),
            }
        return context
    except (TypeError, ValueError):
        return {"error": "Context could not be serialized"}


@dataclass
class MicroPentestConfig:
    """Configuration for micro penetration tests."""

    mpte_url: str = field(
        default_factory=lambda: os.environ.get("MPTE_BASE_URL", "https://mpte:8443")
    )
    verify_ssl: bool = field(
        default_factory=lambda: os.environ.get("MPTE_VERIFY_SSL", "false").lower()
        == "true"
    )
    timeout_seconds: float = 300.0  # 5 minutes for pen tests
    provider: str = "openai"  # Default LLM provider


@dataclass
class MicroPentestResult:
    """Result of a micro penetration test."""

    status: str
    flow_id: Optional[int] = None
    cve_ids: List[str] = field(default_factory=list)
    target_urls: List[str] = field(default_factory=list)
    message: str = ""
    error: Optional[str] = None
    cve_results: Optional[List[Dict[str, Any]]] = None
    findings: Optional[List[Dict[str, Any]]] = None
    scan_metadata: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        result: Dict[str, Any] = {
            "status": self.status,
            "cve_ids": self.cve_ids,
            "target_urls": self.target_urls,
            "message": self.message,
        }
        if self.flow_id is not None:
            result["flow_id"] = self.flow_id
        if self.error:
            result["error"] = self.error
        if self.cve_results is not None:
            result["cve_results"] = self.cve_results
        if self.findings is not None:
            result["findings"] = self.findings
        if self.scan_metadata is not None:
            result["scan_metadata"] = self.scan_metadata
        return result


@dataclass
class MicroPentestStatus:
    """Status of a micro penetration test flow."""

    flow_id: int
    status: str
    progress: int = 0
    tasks: List[Dict[str, Any]] = field(default_factory=list)
    error: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        result = {
            "flow_id": self.flow_id,
            "status": self.status,
            "progress": self.progress,
            "tasks": self.tasks,
        }
        if self.error:
            result["error"] = self.error
        return result


def _get_mpte_client(config: MicroPentestConfig) -> httpx.AsyncClient:
    """Get MPTE API client."""
    return httpx.AsyncClient(
        base_url=config.mpte_url,
        timeout=config.timeout_seconds,
        verify=config.verify_ssl,  # Self-signed certs need verify=False
    )


async def run_micro_pentest(
    cve_ids: List[str],
    target_urls: List[str],
    context: Optional[Dict[str, Any]] = None,
    config: Optional[MicroPentestConfig] = None,
) -> MicroPentestResult:
    """Run micro penetration tests for selected CVEs using MPTE.

    Args:
        cve_ids: List of CVE IDs to test
        target_urls: List of target URLs to test against
        context: Optional context information for the test
        config: Optional configuration (uses defaults if not provided)

    Returns:
        MicroPentestResult with status and flow_id if successful
    """
    if config is None:
        config = MicroPentestConfig()

    # cve_ids can be empty — the scanner will still run a full vulnerability scan
    # against the targets (security headers, CORS, XSS, SQLi, etc.)

    if not target_urls:
        return MicroPentestResult(
            status="error",
            error="At least one target URL is required",
        )

    # Validate CVE IDs to prevent prompt injection
    invalid_cves = [cve for cve in cve_ids if not _validate_cve_id(cve)]
    if invalid_cves:
        return MicroPentestResult(
            status="error",
            error=f"Invalid CVE ID format: {', '.join(invalid_cves[:3])}. Expected format: CVE-YYYY-NNNNN",
        )

    # Validate target URLs to prevent SSRF
    invalid_urls = [url for url in target_urls if not _validate_target_url(url)]
    if invalid_urls:
        return MicroPentestResult(
            status="error",
            error=f"Invalid or blocked target URL: {invalid_urls[0]}. Only http/https URLs to external hosts allowed.",
        )

    # Sanitize context to prevent oversized payloads
    sanitized_context = _sanitize_context(context)

    logger.info(
        f"micro_pentest.start cve_count={len(cve_ids)} target_count={len(target_urls)} cve_ids={cve_ids[:5]}"
    )

    # Prepare MPTE flow request
    mpte_payload: Dict[str, Any] = {
        "input": (
            f"Perform micro penetration tests for CVEs: {', '.join(cve_ids)}. "
            f"Target URLs: {', '.join(target_urls)}. "
            f"Focus on verifying exploitability and impact assessment. "
            f"Test each CVE individually and provide detailed findings."
        ),
        "provider": config.provider,
        "functions": {
            "disabled": [],
            "functions": [],
        },
    }

    # Add context if provided
    if sanitized_context:
        mpte_payload["context"] = sanitized_context

    try:
        async with _get_mpte_client(config) as client:
            response = await client.post(
                "/api/v1/flows",
                json=mpte_payload,
                headers={"Content-Type": "application/json"},
            )

            if response.status_code != 201:
                logger.warning(
                    f"micro_pentest.mpte_error_fallback status_code={response.status_code} "
                    f"response_text={response.text[:200] if response.text else ''} "
                    f"- MPTE returned error, falling back to built-in scanner"
                )
                # Fallback to built-in scanner when MPTE returns errors
                return await _run_builtin_vulnerability_scan(cve_ids, target_urls)

            # MPTE returns: { "data": { "id": ..., ... } } or { "id": ..., ... }
            flow_data = response.json()
            flow_obj = flow_data.get("data", flow_data)
            flow_id = flow_obj.get("id") or flow_obj.get("flow_id")

            # Validate flow_id was returned
            if flow_id is None:
                logger.error(f"micro_pentest.missing_flow_id response_data={flow_data}")
                return MicroPentestResult(
                    status="error",
                    cve_ids=cve_ids,
                    target_urls=target_urls,
                    error="MPTE response missing flow_id",
                )

            logger.info(f"micro_pentest.flow_created flow_id={flow_id}")

            return MicroPentestResult(
                status="started",
                flow_id=flow_id,
                cve_ids=cve_ids,
                target_urls=target_urls,
                message=f"Micro penetration test started for {len(cve_ids)} CVEs",
            )

    except httpx.TimeoutException:
        logger.error("micro_pentest.timeout")
        return MicroPentestResult(
            status="error",
            cve_ids=cve_ids,
            target_urls=target_urls,
            error="MPTE request timeout",
        )
    except httpx.RequestError as e:
        logger.warning(
            f"micro_pentest.mpte_unavailable error={e} - Falling back to built-in real scanner"
        )
        # Fallback to built-in real scanner when MPTE is unavailable
        return await _run_builtin_vulnerability_scan(cve_ids, target_urls)


# ============================================================================
# Advanced Analysis: MITRE ATT&CK, Attack Chains, Compliance, Risk Scoring
# ============================================================================

# MITRE ATT&CK technique mapping for vulnerability types
_VULN_TO_MITRE = {
    "sql_injection": [
        ("T1190", "Exploit Public-Facing Application"),
        ("T1059", "Command and Scripting Interpreter"),
        ("T1565.001", "Stored Data Manipulation"),
    ],
    "xss": [
        ("T1190", "Exploit Public-Facing Application"),
        ("T1059.007", "JavaScript"),
        ("T1185", "Browser Session Forgery"),
    ],
    "command_injection": [
        ("T1059", "Command and Scripting Interpreter"),
        ("T1190", "Exploit Public-Facing Application"),
        ("T1059.004", "Unix Shell"),
    ],
    "path_traversal": [
        ("T1083", "File and Directory Discovery"),
        ("T1005", "Data from Local System"),
        ("T1560", "Archive Collected Data"),
    ],
    "authentication_bypass": [
        ("T1078", "Valid Accounts"),
        ("T1556", "Modify Authentication Process"),
        ("T1548", "Abuse Elevation Control Mechanism"),
    ],
    "security_headers": [
        ("T1189", "Drive-by Compromise"),
        ("T1557", "Adversary-in-the-Middle"),
    ],
    "ssl_tls": [
        ("T1557", "Adversary-in-the-Middle"),
        ("T1040", "Network Sniffing"),
        ("T1557.002", "ARP Cache Poisoning"),
    ],
    "information_disclosure": [
        ("T1592", "Gather Victim Host Info"),
        ("T1590", "Gather Victim Network Info"),
        ("T1592.004", "Client Configurations"),
    ],
    "cors_misconfiguration": [
        ("T1189", "Drive-by Compromise"),
        ("T1557", "Adversary-in-the-Middle"),
        ("T1185", "Browser Session Forgery"),
    ],
    "cookie_security": [
        ("T1539", "Steal Web Session Cookie"),
        ("T1550.004", "Web Session Cookie"),
        ("T1185", "Browser Session Forgery"),
    ],
    "http_method_exposure": [
        ("T1595", "Active Scanning"),
        ("T1190", "Exploit Public-Facing Application"),
    ],
    "technology_fingerprint": [
        ("T1592", "Gather Victim Host Info"),
        ("T1595", "Active Scanning"),
        ("T1592.002", "Software"),
    ],
    "open_redirect": [
        ("T1566.002", "Spearphishing Link"),
        ("T1204.001", "Malicious Link"),
        ("T1598", "Phishing for Information"),
    ],
    "crlf_injection": [
        ("T1190", "Exploit Public-Facing Application"),
        ("T1557", "Adversary-in-the-Middle"),
        ("T1036", "Masquerading"),
    ],
    "api_exposure": [
        ("T1595.002", "Vulnerability Scanning"),
        ("T1190", "Exploit Public-Facing Application"),
        ("T1530", "Data from Cloud Storage"),
    ],
    "cve_vulnerability": [
        ("T1190", "Exploit Public-Facing Application"),
        ("T1210", "Exploitation of Remote Services"),
        ("T1203", "Exploitation for Client Execution"),
    ],
    "ssti": [
        ("T1190", "Exploit Public-Facing Application"),
        ("T1059", "Command and Scripting Interpreter"),
        ("T1203", "Exploitation for Client Execution"),
    ],
    "http_request_smuggling": [
        ("T1190", "Exploit Public-Facing Application"),
        ("T1557", "Adversary-in-the-Middle"),
        ("T1036", "Masquerading"),
    ],
    "host_header_injection": [
        ("T1557", "Adversary-in-the-Middle"),
        ("T1189", "Drive-by Compromise"),
        ("T1036", "Masquerading"),
    ],
    "deserialization": [
        ("T1190", "Exploit Public-Facing Application"),
        ("T1059", "Command and Scripting Interpreter"),
        ("T1203", "Exploitation for Client Execution"),
    ],
    "cache_poisoning": [
        ("T1557", "Adversary-in-the-Middle"),
        ("T1189", "Drive-by Compromise"),
        ("T1565.002", "Transmitted Data Manipulation"),
    ],
    "ssrf": [
        ("T1190", "Exploit Public-Facing Application"),
        ("T1106", "Native API"),
        ("T1005", "Data from Local System"),
    ],
    "secrets_exposure": [
        ("T1552", "Unsecured Credentials"),
        ("T1552.001", "Credentials In Files"),
        ("T1528", "Steal Application Access Token"),
    ],
}

# Compliance framework controls
_COMPLIANCE_CONTROLS = {
    "PCI-DSS": {
        "6.5.1": {
            "name": "Injection flaws",
            "vuln_types": ["sql_injection", "command_injection", "crlf_injection"],
        },
        "6.5.7": {"name": "Cross-site scripting", "vuln_types": ["xss"]},
        "6.5.10": {
            "name": "Broken authentication",
            "vuln_types": ["authentication_bypass", "cookie_security"],
        },
        "4.1": {
            "name": "Strong cryptography for transmission",
            "vuln_types": ["ssl_tls"],
        },
        "6.6": {"name": "Web application firewall", "vuln_types": ["waf_detection"]},
        "6.5.4": {
            "name": "Insecure communications",
            "vuln_types": ["cors_misconfiguration", "security_headers"],
        },
    },
    "SOC2": {
        "CC6.1": {
            "name": "Logical and physical access controls",
            "vuln_types": ["authentication_bypass", "api_exposure"],
        },
        "CC6.6": {
            "name": "Security measures against threats",
            "vuln_types": ["sql_injection", "xss", "command_injection"],
        },
        "CC6.7": {
            "name": "Transmission data protection",
            "vuln_types": ["ssl_tls", "security_headers"],
        },
        "CC7.1": {
            "name": "Detect and monitor anomalies",
            "vuln_types": ["information_disclosure", "technology_fingerprint"],
        },
    },
    "HIPAA": {
        "164.312(a)(1)": {
            "name": "Access control",
            "vuln_types": ["authentication_bypass", "api_exposure"],
        },
        "164.312(e)(1)": {
            "name": "Transmission security",
            "vuln_types": ["ssl_tls", "security_headers"],
        },
        "164.312(c)(1)": {
            "name": "Integrity controls",
            "vuln_types": ["sql_injection", "command_injection"],
        },
    },
    "GDPR": {
        "Art.25": {
            "name": "Data protection by design",
            "vuln_types": ["information_disclosure", "path_traversal"],
        },
        "Art.32": {
            "name": "Security of processing",
            "vuln_types": ["sql_injection", "xss", "ssl_tls", "authentication_bypass"],
        },
        "Art.5(1)(f)": {
            "name": "Integrity and confidentiality",
            "vuln_types": ["cors_misconfiguration", "cookie_security"],
        },
    },
}


def _deduplicate_findings(findings: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """De-duplicate findings by (target, vulnerability_type, title).

    For cookie findings, group by (target, cookie_name) and merge issues.
    Also drops deprecated or context-irrelevant findings:
      - X-XSS-Protection (deprecated; modern browsers ignore it)
      - Missing X-Frame-Options / CSP on JSON API endpoints (irrelevant)
    """
    # Phase 1: filter out deprecated / irrelevant findings
    filtered: List[Dict[str, Any]] = []
    for f in findings:
        title = f.get("title", "")
        # X-XSS-Protection is deprecated — modern browsers ignore it
        if "X-XSS-Protection" in title:
            continue
        # Missing X-Frame-Options on JSON-only APIs is not meaningful
        evidence = f.get("evidence", {})
        content_type = str(evidence.get("content_type", ""))
        if "X-Frame-Options" in title and "json" in content_type.lower():
            continue
        filtered.append(f)

    # Phase 2: de-duplicate (target, type, title) — keep first occurrence
    seen: set = set()
    deduped: List[Dict[str, Any]] = []
    for f in filtered:
        key = (
            f.get("target", ""),
            f.get("type", f.get("vulnerability_type", "")),
            f.get("title", ""),
        )
        if key in seen:
            continue
        seen.add(key)
        deduped.append(f)

    # Phase 3: merge cookie findings per (target, cookie_name)
    cookie_key_map: Dict[tuple, Dict[str, Any]] = {}
    non_cookie: List[Dict[str, Any]] = []
    for f in deduped:
        vtype = str(f.get("type", f.get("vulnerability_type", "")))
        if "cookie" in vtype.lower():
            evidence = f.get("evidence", {})
            cname = evidence.get("cookie_name", f.get("title", ""))
            key = (f.get("target", ""), cname)
            if key not in cookie_key_map:
                cookie_key_map[key] = f
            else:
                # Merge issues lists
                existing_issues = (
                    cookie_key_map[key].get("evidence", {}).get("issues", [])
                )
                new_issues = evidence.get("issues", [])
                merged = list(dict.fromkeys(existing_issues + new_issues))
                cookie_key_map[key].setdefault("evidence", {})["issues"] = merged
        else:
            non_cookie.append(f)

    return non_cookie + list(cookie_key_map.values())


def _map_findings_to_mitre(
    findings: List[Dict[str, Any]], cve_results: List[Dict[str, Any]]
) -> List[Dict[str, Any]]:
    """Map all findings to MITRE ATT&CK techniques."""
    techniques = []
    seen = set()
    for f in findings:
        vuln_type = _normalize_vuln_type(f.get("vulnerability_type", f.get("type", "")))
        mappings = _VULN_TO_MITRE.get(
            vuln_type, _VULN_TO_MITRE.get("cve_vulnerability", [])
        )
        for tid, tname in mappings:
            if tid not in seen:
                seen.add(tid)
                techniques.append(
                    {
                        "technique_id": tid,
                        "technique_name": tname,
                        "phase": _mitre_phase(tid),
                        "triggered_by": f.get("title", f.get("type", "unknown")),
                        "severity": f.get("severity", "medium"),
                    }
                )
    for cr in cve_results:
        if cr.get("vulnerable"):
            for tid, tname in _VULN_TO_MITRE.get("cve_vulnerability", []):
                if tid not in seen:
                    seen.add(tid)
                    techniques.append(
                        {
                            "technique_id": tid,
                            "technique_name": tname,
                            "phase": _mitre_phase(tid),
                            "triggered_by": cr.get("cve_id", "unknown"),
                            "severity": cr.get("severity", "critical"),
                        }
                    )
    return techniques


def _mitre_phase(tid: str) -> str:
    """Resolve MITRE ATT&CK kill-chain phase from technique ID."""
    phase_map = {
        "T1190": "initial_access",
        "T1189": "initial_access",
        "T1566": "initial_access",
        "T1059": "execution",
        "T1204": "execution",
        "T1078": "defense_evasion",
        "T1556": "defense_evasion",
        "T1539": "credential_access",
        "T1040": "credential_access",
        "T1550": "credential_access",
        "T1083": "discovery",
        "T1592": "discovery",
        "T1590": "discovery",
        "T1595": "discovery",
        "T1005": "collection",
        "T1557": "collection",
        "T1210": "lateral_movement",
    }
    base = tid.split(".")[0]
    return phase_map.get(tid, phase_map.get(base, "unknown"))


def _build_attack_chains(
    findings: List[Dict[str, Any]],
    cve_results: List[Dict[str, Any]],
    mitre_techniques: List[Dict[str, Any]],
) -> List[Dict[str, Any]]:
    """Build multi-step attack chains from findings and MITRE techniques."""
    chains = []
    # Group techniques by kill-chain phase
    phases_order = [
        "initial_access",
        "execution",
        "defense_evasion",
        "credential_access",
        "discovery",
        "lateral_movement",
        "collection",
    ]
    phase_techs = {}
    for t in mitre_techniques:
        p = t["phase"]
        if p not in phase_techs:
            phase_techs[p] = []
        phase_techs[p].append(t)

    # Build chain: Initial Access → Execution → further phases
    entry_points = phase_techs.get("initial_access", [])
    for ep in entry_points:
        chain = {
            "entry_point": ep["triggered_by"],
            "steps": [
                {
                    "phase": "initial_access",
                    "technique": ep["technique_id"],
                    "name": ep["technique_name"],
                    "finding": ep["triggered_by"],
                }
            ],
        }
        for phase in phases_order[1:]:
            if phase in phase_techs:
                step = phase_techs[phase][0]
                chain["steps"].append(
                    {
                        "phase": phase,
                        "technique": step["technique_id"],
                        "name": step["technique_name"],
                        "finding": step["triggered_by"],
                    }
                )
        # Calculate chain risk
        chain["depth"] = len(chain["steps"])
        chain["risk_level"] = (
            "critical"
            if chain["depth"] >= 4
            else "high"
            if chain["depth"] >= 3
            else "medium"
        )
        chains.append(chain)

    # Also build a "data exfiltration" chain if we have both discovery and collection
    if "discovery" in phase_techs and "collection" in phase_techs:
        chains.append(
            {
                "entry_point": "Information Gathering → Data Exfiltration",
                "steps": [
                    {
                        "phase": "discovery",
                        "technique": phase_techs["discovery"][0]["technique_id"],
                        "name": phase_techs["discovery"][0]["technique_name"],
                        "finding": phase_techs["discovery"][0]["triggered_by"],
                    },
                    {
                        "phase": "collection",
                        "technique": phase_techs["collection"][0]["technique_id"],
                        "name": phase_techs["collection"][0]["technique_name"],
                        "finding": phase_techs["collection"][0]["triggered_by"],
                    },
                ],
                "depth": 2,
                "risk_level": "high",
            }
        )
    return chains


def _validate_compliance(
    findings: List[Dict[str, Any]], cve_results: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """Validate findings against compliance frameworks."""
    results = {}
    vuln_types_present = set()
    for f in findings:
        vt = _normalize_vuln_type(f.get("vulnerability_type", f.get("type", "")))
        vuln_types_present.add(vt)
    # Critical CVEs automatically trigger compliance issues
    has_critical = any(
        cr.get("vulnerable") and cr.get("severity") in ("critical", "high")
        for cr in cve_results
    )
    if has_critical:
        vuln_types_present.add("cve_critical")

    for framework, controls in _COMPLIANCE_CONTROLS.items():
        violations = []
        for ctrl_id, ctrl in controls.items():
            matched = [vt for vt in ctrl["vuln_types"] if vt in vuln_types_present]
            if matched:
                violations.append(
                    {
                        "control": ctrl_id,
                        "name": ctrl["name"],
                        "triggered_by": matched,
                        "status": "non_compliant",
                    }
                )
        total = len(controls)
        passing = total - len(violations)
        results[framework] = {
            "total_controls": total,
            "passing": passing,
            "failing": len(violations),
            "compliance_pct": round(passing / total * 100, 1) if total > 0 else 100.0,
            "violations": violations,
            "status": "non_compliant" if violations else "compliant",
        }
    return results


def _compute_risk_score(
    findings: List[Dict[str, Any]],
    cve_results: List[Dict[str, Any]],
    attack_chains: List[Dict[str, Any]],
    compliance: Dict[str, Any],
) -> Dict[str, Any]:
    """Compute contextual risk score (0.0-10.0)."""
    score = 0.0
    factors = []

    # Factor 1: CVSS-weighted vulnerability score (max 4.0)
    cvss_scores = [
        f.get("cvss_score", 0.0) for f in findings if f.get("cvss_score")
    ] + [cr.get("cvss_score", 0.0) for cr in cve_results if cr.get("vulnerable")]
    if cvss_scores:
        max_cvss = max(cvss_scores)
        avg_cvss = sum(cvss_scores) / len(cvss_scores)
        vuln_score = min(4.0, (max_cvss * 0.6 + avg_cvss * 0.4) / 2.5)
        score += vuln_score
        factors.append(
            {
                "factor": "vulnerability_severity",
                "contribution": round(vuln_score, 2),
                "detail": f"Max CVSS {max_cvss}, Avg {avg_cvss:.1f}",
            }
        )

    # Factor 2: Attack chain depth (max 2.5)
    if attack_chains:
        max_depth = max(c["depth"] for c in attack_chains)
        chain_score = min(2.5, max_depth * 0.6)
        score += chain_score
        factors.append(
            {
                "factor": "attack_chain_depth",
                "contribution": round(chain_score, 2),
                "detail": f"{len(attack_chains)} chains, max depth {max_depth}",
            }
        )

    # Factor 3: Finding volume (max 1.5)
    finding_count = len(findings)
    vol_score = min(1.5, finding_count * 0.1)
    score += vol_score
    factors.append(
        {
            "factor": "finding_volume",
            "contribution": round(vol_score, 2),
            "detail": f"{finding_count} total findings",
        }
    )

    # Factor 4: Compliance failures (max 2.0)
    total_violations = sum(fw.get("failing", 0) for fw in compliance.values())
    comp_score = min(2.0, total_violations * 0.25)
    score += comp_score
    factors.append(
        {
            "factor": "compliance_violations",
            "contribution": round(comp_score, 2),
            "detail": f"{total_violations} control violations",
        }
    )

    score = min(10.0, round(score, 1))
    level = (
        "critical"
        if score >= 8.0
        else "high"
        if score >= 6.0
        else "medium"
        if score >= 3.5
        else "low"
    )

    return {"score": score, "level": level, "max_score": 10.0, "factors": factors}


def _generate_executive_summary(
    cve_results: List[Dict[str, Any]],
    findings: List[Dict[str, Any]],
    mitre_techniques: List[Dict[str, Any]],
    attack_chains: List[Dict[str, Any]],
    compliance: Dict[str, Any],
    risk: Dict[str, Any],
) -> Dict[str, Any]:
    """Generate executive summary with business impact analysis."""
    confirmed_cves = [
        cr for cr in cve_results if cr.get("verdict") == "VULNERABLE_VERIFIED"
    ]
    unverified_cves = [cr for cr in cve_results if cr.get("verdict") == "UNVERIFIED"]
    not_applicable_cves = [
        cr for cr in cve_results if cr.get("verdict") == "NOT_APPLICABLE"
    ]
    verified_safe_cves = [
        cr for cr in cve_results if cr.get("verdict") == "NOT_VULNERABLE_VERIFIED"
    ]
    critical_findings = [
        f for f in findings if f.get("severity") in ("critical", "high")
    ]
    non_compliant = [
        fw for fw, data in compliance.items() if data["status"] == "non_compliant"
    ]

    # Top risks
    top_risks = []
    if confirmed_cves:
        top_risks.append(
            f"{len(confirmed_cves)} CVE(s) confirmed exploitable — immediate patching required"
        )
    if unverified_cves:
        top_risks.append(
            f"{len(unverified_cves)} CVE(s) could not be verified — manual assessment recommended"
        )
    if any(c["depth"] >= 4 for c in attack_chains):
        top_risks.append(
            "Multi-stage attack chain detected — adversary can pivot from initial access to data exfiltration"
        )
    if critical_findings:
        top_risks.append(
            f"{len(critical_findings)} critical/high severity findings need urgent remediation"
        )
    if non_compliant:
        top_risks.append(
            f"Non-compliant with {', '.join(non_compliant)} — regulatory risk"
        )

    # Prioritized actions
    actions = []
    for cr in sorted(
        confirmed_cves, key=lambda x: x.get("cvss_score", 0), reverse=True
    )[:3]:
        actions.append(
            {
                "priority": "P0",
                "action": f"Patch {cr['cve_id']} (CVSS {cr.get('cvss_score', 0)})",
                "detail": cr.get("remediation", ""),
            }
        )
    for cr in sorted(
        unverified_cves, key=lambda x: x.get("cvss_score", 0), reverse=True
    )[:2]:
        actions.append(
            {
                "priority": "P1",
                "action": f"Verify {cr['cve_id']} — no exploit test available",
                "detail": cr.get("how_to_verify", cr.get("remediation", "")),
            }
        )
    for f in sorted(
        critical_findings, key=lambda x: x.get("cvss_score", 0), reverse=True
    )[:3]:
        actions.append(
            {
                "priority": "P1",
                "action": f"Fix {f.get('title', f.get('type', 'unknown'))}",
                "detail": f.get("remediation", ""),
            }
        )

    return {
        "risk_level": risk["level"],
        "risk_score": risk["score"],
        "headline": (
            f"Risk Level: {risk['level'].upper()} ({risk['score']}/10) — "
            f"{len(confirmed_cves)} confirmed vulnerable, "
            f"{len(unverified_cves)} unverified, "
            f"{len(not_applicable_cves)} not applicable, "
            f"{len(findings)} total findings"
        ),
        "top_risks": top_risks,
        "prioritized_actions": actions[:5],
        "compliance_summary": {fw: data["status"] for fw, data in compliance.items()},
        "verdict_summary": {
            "confirmed_vulnerable": len(confirmed_cves),
            "verified_safe": len(verified_safe_cves),
            "not_applicable": len(not_applicable_cves),
            "unverified": len(unverified_cves),
        },
        "attack_surface": {
            "total_findings": len(findings),
            "critical_high": len(critical_findings),
            "exploitable_cves": len(confirmed_cves),
            "attack_chains": len(attack_chains),
            "mitre_techniques": len(mitre_techniques),
        },
    }


# ── Exploitable finding types and their evidence keys ───────────────
# Findings of these types are REAL exploits when they have supporting evidence.
# They get promoted to VULNERABLE_VERIFIED entries and shown as verified exploits.
_EXPLOITABLE_VULN_TYPES: Dict[str, Dict[str, Any]] = {
    "cors_misconfiguration": {
        "evidence_keys": ["origin_sent", "acao"],
        "severity_fn": lambda ev: "high"
        if ev.get("acac", "").lower() == "true"
        else "medium",
        "cvss_fn": lambda ev: 7.5 if ev.get("acac", "").lower() == "true" else 5.3,
        "cwe": "CWE-942",
        "proof_label": "Server reflects arbitrary Origin",
        "how_to_verify": (
            "1. Send a request with an arbitrary Origin header:\n"
            "   curl -sD- -H 'Origin: https://evil.example.com' '{target}'\n"
            "2. Check the response headers for:\n"
            "   Access-Control-Allow-Origin: https://evil.example.com\n"
            "   Access-Control-Allow-Credentials: true\n"
            "3. If BOTH are present → the server trusts ANY origin with credentials.\n"
            "   An attacker's page can read authenticated API responses cross-origin."
        ),
    },
    "host_header_injection": {
        "evidence_keys": ["injected_host", "reflected"],
        "severity_fn": lambda ev: "high",
        "cvss_fn": lambda ev: 7.5,
        "cwe": "CWE-644",
        "proof_label": "Injected Host reflected in response body",
        "how_to_verify": (
            "1. Send a baseline request (normal Host):\n"
            "   curl -sk '{target}' -o baseline.html\n"
            "2. Send an evil request with injected Host header:\n"
            "   curl -sk -H 'Host: aldeci-evil.example.com' '{target}' -o evil.html\n"
            "3. Check if the canary appears in the evil response:\n"
            "   grep 'aldeci-evil.example.com' evil.html\n"
            "4. Verify it does NOT appear in the baseline:\n"
            "   grep 'aldeci-evil.example.com' baseline.html\n"
            "5. If canary is in evil.html but NOT baseline.html → CONFIRMED.\n"
            "   Impact: cache poisoning, password reset hijacking, phishing."
        ),
    },
    "open_redirect": {
        "evidence_keys": ["parameter", "location_header"],
        "severity_fn": lambda ev: "medium",
        "cvss_fn": lambda ev: 6.1,
        "cwe": "CWE-601",
        "proof_label": "Server redirects to attacker-controlled URL",
        "how_to_verify": (
            "1. Append a redirect parameter pointing to an external domain:\n"
            "   curl -sD- '{target}?{param}=https://evil.example.com' --max-redirs 0\n"
            "2. Check the Location header in the 3xx response:\n"
            "   If Location hostname is evil.example.com → CONFIRMED.\n"
            "3. This allows phishing: victim trusts the original domain in the URL\n"
            "   but gets redirected to the attacker's site."
        ),
    },
    "crlf_injection": {
        "evidence_keys": ["parameter"],
        "severity_fn": lambda ev: "high",
        "cvss_fn": lambda ev: 7.2,
        "cwe": "CWE-93",
        "proof_label": "CRLF characters injected into HTTP response",
        "how_to_verify": (
            "1. Inject CRLF characters into a URL parameter:\n"
            "   curl -sD- '{target}?param=value%0d%0aInjected-Header:true'\n"
            "2. Check if 'Injected-Header: true' appears in the response headers.\n"
            "3. If it does → the server is vulnerable to header injection.\n"
            "   Impact: session fixation, XSS via injected headers, cache poisoning."
        ),
    },
    "sql_injection": {
        "evidence_keys": ["parameter"],
        "severity_fn": lambda ev: "critical",
        "cvss_fn": lambda ev: 9.8,
        "cwe": "CWE-89",
        "proof_label": "SQL injection confirmed via error/timing differential",
        "how_to_verify": (
            "1. Send a normal request and note the response time:\n"
            "   time curl -s '{target}?{param}=1'\n"
            "2. Send a time-based blind SQLi payload:\n"
            '   time curl -s "{target}?{param}=1\' AND SLEEP(5)--"\n'
            "3. If the second request takes ~5s longer → timing-based SQLi confirmed.\n"
            "4. Alternatively, check for SQL error messages in responses.\n"
            "   Impact: full database read/write, data exfiltration, RCE."
        ),
    },
    "xss": {
        "evidence_keys": ["parameter"],
        "severity_fn": lambda ev: "high",
        "cvss_fn": lambda ev: 7.1,
        "cwe": "CWE-79",
        "proof_label": "XSS payload reflected in response",
        "how_to_verify": (
            "1. Inject a unique canary string into the parameter:\n"
            "   curl -s '{target}?{param}=<script>alert(1)</script>'\n"
            "2. Check if the payload appears unescaped in the response body.\n"
            "3. Open in browser with DevTools console to confirm script execution.\n"
            "   Impact: session hijacking, credential theft, defacement."
        ),
    },
    "ssti": {
        "evidence_keys": ["parameter"],
        "severity_fn": lambda ev: "critical",
        "cvss_fn": lambda ev: 9.8,
        "cwe": "CWE-1336",
        "proof_label": "Template expression evaluated by server",
        "how_to_verify": (
            "1. Inject a math expression in the parameter:\n"
            "   curl -s '{target}?{param}={{{{7*7}}}}'\n"
            "2. Check if '49' appears in the response (expression was evaluated).\n"
            "3. Try {{{{config}}}} or {{{{self.__class__.__mro__}}}} for deeper proof.\n"
            "   Impact: Remote Code Execution — full server compromise."
        ),
    },
    "http_request_smuggling": {
        "evidence_keys": ["differential"],
        "severity_fn": lambda ev: "high",
        "cvss_fn": lambda ev: 8.1,
        "cwe": "CWE-444",
        "proof_label": "Differential response indicates request smuggling",
        "how_to_verify": (
            "1. Send a CL.TE smuggling probe:\n"
            "   printf 'POST / HTTP/1.1\\r\\nHost: {host}\\r\\n"
            "Content-Length: 6\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n"
            "0\\r\\n\\r\\nG' | nc {host} 443\n"
            "2. If the next request gets a 405 or different response → smuggling works.\n"
            "3. Use Burp Suite Turbo Intruder for automated detection.\n"
            "   Impact: bypass WAF, hijack other users' requests, cache poisoning."
        ),
    },
    "cache_poisoning": {
        "evidence_keys": ["differential"],
        "severity_fn": lambda ev: "high",
        "cvss_fn": lambda ev: 7.5,
        "cwe": "CWE-349",
        "proof_label": "Cache key collision exploitable",
        "how_to_verify": (
            "1. Send a request with an unkeyed header containing a canary:\n"
            "   curl -sD- -H 'X-Forwarded-Host: evil.example.com' '{target}'\n"
            "2. Check if the canary appears in the response body.\n"
            "3. Send a normal request to the same URL:\n"
            "   curl -sD- '{target}'\n"
            "4. If the canary appears in the normal response → cache is poisoned.\n"
            "   Impact: all users served malicious content from the cache."
        ),
    },
}


def _normalize_vuln_type(raw: str) -> str:
    """Normalize enum string representations to plain lowercase keys.

    ``VulnerabilityType.CORS_MISCONFIGURATION`` → ``cors_misconfiguration``
    ``general_vuln_scan``                        → ``general_vuln_scan``
    """
    s = str(raw)
    return s.split(".")[-1].lower() if "." in s else s.lower()


def _render_how_to_verify(
    meta: Dict[str, Any], target: str, evidence: Dict[str, Any]
) -> str:
    """Render the how_to_verify template with concrete values from the finding."""
    template = meta.get("how_to_verify", "")
    if not template:
        return ""
    from urllib.parse import urlparse

    parsed = urlparse(target)
    host = parsed.hostname or parsed.netloc or target
    param = evidence.get("parameter", "param")
    return template.format(target=target, host=host, param=param)


def _promote_exploitable_findings(
    findings: List[Dict[str, Any]],
) -> List[Dict[str, Any]]:
    """Promote general findings with exploitation evidence to VULNERABLE_VERIFIED.

    Returns a list of verified-exploit dicts (same schema as cve_results) that
    should be prepended to the cve_results list so they appear in the report's
    "Confirmed Vulnerable" section.
    """
    verified_exploits: List[Dict[str, Any]] = []
    for f in findings:
        vuln_type = _normalize_vuln_type(f.get("vulnerability_type", f.get("type", "")))
        meta = _EXPLOITABLE_VULN_TYPES.get(vuln_type)
        if meta is None:
            continue
        evidence = f.get("evidence", {})
        # Check that the required evidence keys are present and truthy
        if not all(evidence.get(k) for k in meta["evidence_keys"]):
            continue
        # Build a cve_results-style entry
        target = f.get("target", "")
        sev = meta["severity_fn"](evidence)
        cvss = meta["cvss_fn"](evidence)
        # Build human-readable proof string from evidence
        proof_parts = [meta["proof_label"]]
        for k in meta["evidence_keys"]:
            v = evidence.get(k)
            if v is not None and v is not True:
                proof_parts.append(f"{k}={v}")
        proof_str = " | ".join(proof_parts)
        verified_exploits.append(
            {
                "cve_id": f"FINDING-{vuln_type.upper().replace('_', '-')}",
                "target_url": target,
                "vulnerable": True,
                "confidence": 0.95,
                "severity": sev,
                "cvss_score": cvss,
                "description": f.get("description", ""),
                "remediation": f.get("remediation", ""),
                "test_method": "real_scanner_exploit_verification",
                "evidence": {
                    **evidence,
                    "proof": proof_str,
                    "verification_method": "differential_analysis"
                    if evidence.get("differential")
                    else "response_analysis",
                },
                "verification_chain": "scan→detect→exploit→verify",
                "verdict": "VULNERABLE_VERIFIED",
                "applicability_score": 100,
                "test_coverage_score": 90,
                "confidence_score": 95,
                "how_to_verify": _render_how_to_verify(meta, target, evidence),
                "title": f.get("title", ""),
                "cwe_id": meta["cwe"],
                "finding_type": "verified_exploit",
            }
        )
    return verified_exploits


def _generate_poc_commands(
    cve_results: List[Dict[str, Any]], findings: List[Dict[str, Any]]
) -> List[Dict[str, Any]]:
    """Auto-generate PoC (Proof-of-Concept) curl commands for reproduction."""
    pocs = []

    # PoCs for CVE-based and promoted verified exploits
    for cr in cve_results:
        if not cr.get("vulnerable") and cr.get("verdict") != "VULNERABLE_VERIFIED":
            continue
        evidence = cr.get("evidence", {})
        target = cr.get("target_url", "")
        cve_id = cr.get("cve_id", "")

        # ── Promoted exploit findings ──
        finding_type = cr.get("finding_type", "")
        if finding_type == "verified_exploit":
            vuln_type = cve_id.replace("FINDING-", "").replace("-", "_").lower()
            if vuln_type == "cors_misconfiguration":
                origin = evidence.get("origin_sent", "https://evil.com")
                pocs.append(
                    {
                        "type": "CORS Misconfiguration",
                        "target": target,
                        "curl_command": f"curl -sD- -H 'Origin: {origin}' '{target}' | grep -i 'access-control'",
                        "description": f"CORS: server reflects origin '{origin}'"
                        + (
                            ", credentials allowed"
                            if evidence.get("acac", "").lower() == "true"
                            else ""
                        ),
                    }
                )
            elif vuln_type == "host_header_injection":
                injected = evidence.get("injected_host", "evil.example.com")
                pocs.append(
                    {
                        "type": "Host Header Injection",
                        "target": target,
                        "curl_command": f"curl -sD- -H 'Host: {injected}' '{target}' | grep -i '{injected}'",
                        "description": f"Host header injection: '{injected}' reflected in response body",
                    }
                )
            elif vuln_type == "open_redirect":
                param = evidence.get("parameter", "url")
                redir = evidence.get("redirect_target", "https://evil.example.com")
                pocs.append(
                    {
                        "type": "Open Redirect",
                        "target": target,
                        "curl_command": f"curl -sD- '{target}?{param}={redir}' | grep -i 'location'",
                        "description": f"Open redirect via '{param}' parameter to '{redir}'",
                    }
                )
            elif vuln_type in ("crlf_injection", "sql_injection", "xss", "ssti"):
                param = evidence.get("parameter", "")
                payload = evidence.get("payload", "")
                if param:
                    pocs.append(
                        {
                            "type": vuln_type.replace("_", " ").title(),
                            "target": target,
                            "curl_command": f"curl -v '{target}?{param}={payload}'",
                            "description": f"Reproduce {vuln_type.replace('_', ' ')} on '{param}'",
                        }
                    )
            continue

        # ── Standard CVE PoCs ──
        tests_run = evidence.get("tests_run", [])
        for test in tests_run:
            if isinstance(test, dict):
                method = test.get("method", "GET")
                hdrs = test.get("headers", {})
                path = test.get("path", "")
                payload = test.get("payload", "")
                url = target.rstrip("/") + path if path else target
                curl_parts = ["curl -s -o /dev/null -w '%{http_code}'"]
                if method != "GET":
                    curl_parts.append(f"-X {method}")
                for k, v in (hdrs if isinstance(hdrs, dict) else {}).items():
                    curl_parts.append(f"-H '{k}: {v}'")
                if payload:
                    curl_parts.append(f"-d '{payload}'")
                curl_parts.append(f"'{url}'")
                pocs.append(
                    {
                        "cve_id": cve_id,
                        "target": target,
                        "curl_command": " ".join(curl_parts),
                        "description": f"Reproduce {cve_id} against {target}",
                    }
                )
                break  # One PoC per CVE
        if not tests_run:
            pocs.append(
                {
                    "cve_id": cve_id,
                    "target": target,
                    "curl_command": f"curl -v '{target}'",
                    "description": f"Basic connectivity test for {cve_id}",
                }
            )

    return pocs


def _filter_false_positives(
    cve_results: List[Dict[str, Any]], findings: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """Flag likely false positives and compute accuracy metrics using verdict taxonomy."""
    fp_cves = []
    verified_cves = []
    for cr in cve_results:
        verdict = cr.get("verdict", "UNVERIFIED")
        # Only VULNERABLE_VERIFIED needs FP analysis; others are correctly classified
        if verdict != "VULNERABLE_VERIFIED":
            continue
        conf = cr.get("confidence", 0.0)
        if conf < 0.60:
            fp_cves.append(
                {
                    "cve_id": cr.get("cve_id"),
                    "target": cr.get("target_url"),
                    "reason": f"Confidence {conf:.0%} below 60% threshold despite VULNERABLE verdict",
                }
            )
        else:
            verified_cves.append(
                {
                    "cve_id": cr.get("cve_id"),
                    "target": cr.get("target_url"),
                    "confidence": conf,
                }
            )

    fp_findings = []
    verified_findings = []
    # Deterministic vulnerability types — these checks are inherently accurate
    # (e.g., a header either exists or it doesn't; no false positive possible)
    _DETERMINISTIC_VULN_TYPES = {
        "security_headers",
        "cookie_security",
        "information_disclosure",
        "technology_fingerprint",
        "waf_detection",
        "ssl_tls",
        "http_method_exposure",
        "api_exposure",
        "cors_misconfiguration",
        "host_header_injection",
        "open_redirect",
    }
    for f in findings:
        sev = f.get("severity", "unknown")
        evidence = f.get("evidence", {})
        vuln_type = _normalize_vuln_type(f.get("vulnerability_type", ""))
        title = f.get("title", f.get("type", "unknown"))
        # Differential analysis is the gold standard for injection-type vulns
        if evidence.get("differential"):
            verified_findings.append(title)
        elif sev in ("info",):
            # Info-level findings are never false positives
            verified_findings.append(title)
        elif vuln_type in _DETERMINISTIC_VULN_TYPES:
            # Deterministic checks: header present/absent, cookie flags, version strings
            verified_findings.append(title)
        elif any(
            kw in title.lower()
            for kw in (
                "missing",
                "header",
                "cookie",
                "version",
                "disclosure",
                "fingerprint",
                "waf",
                "cdn",
                "endpoint",
                "discovery",
                "host header injection",
            )
        ):
            # Title-based fallback for deterministic findings
            verified_findings.append(title)
        else:
            fp_findings.append(title)

    total_flagged = len(
        [cr for cr in cve_results if cr.get("verdict") == "VULNERABLE_VERIFIED"]
    ) + len(findings)
    total_verified = len(verified_cves) + len(verified_findings)
    accuracy = (total_verified / total_flagged * 100) if total_flagged > 0 else 100.0

    return {
        "likely_false_positive_cves": fp_cves,
        "verified_cves": verified_cves,
        "likely_false_positive_findings": fp_findings,
        "verified_findings": verified_findings,
        "estimated_accuracy": round(accuracy, 1),
        "total_flagged": total_flagged,
        "total_verified": total_verified,
    }


# ============================================================================
# AI-Powered Analysis Layer (PentAGI Multi-AI Consensus)
# ============================================================================


async def _run_ai_analysis(
    cve_results: List[Dict[str, Any]],
    findings: List[Dict[str, Any]],
    target_urls: List[str],
) -> Dict[str, Any]:
    """Run AI-powered analysis on scan results using MultiAIOrchestrator.

    Uses 3 LLM providers in parallel:
    - Gemini (Architect): Attack surface analysis, business impact
    - Claude (Developer): Exploitability assessment, payload design
    - GPT-4 (Team Lead): Strategy, risk assessment, success criteria

    Returns ai_analysis metadata dict. Gracefully degrades if LLMs unavailable.
    """
    ai_meta: Dict[str, Any] = {
        "ai_enabled": False,
        "providers_used": [],
        "providers_available": {},
        "consensus_decisions": 0,
        "total_llm_calls": 0,
        "successful_llm_calls": 0,
        "fallback_llm_calls": 0,
        "exploit_strategies_generated": 0,
        "ai_risk_assessments": [],
        "consensus_config": {},
        "ai_enhanced_findings": [],
        "duration_seconds": 0.0,
    }

    t0 = time.time()

    try:
        from core.exploit_generator import IntelligentExploitGenerator
        from core.llm_providers import LLMProviderManager
        from core.mpte_advanced import MultiAIOrchestrator

        llm_manager = LLMProviderManager()

        # Check which providers have real API keys
        for name in ("openai", "anthropic", "gemini"):
            provider = llm_manager.get_provider(name)
            has_key = bool(getattr(provider, "api_key", None))
            ai_meta["providers_available"][name] = has_key

        any_provider_available = any(ai_meta["providers_available"].values())
        if not any_provider_available:
            logger.info("micro_pentest.ai_analysis_skipped reason=no_api_keys")
            ai_meta["skip_reason"] = "no_api_keys_configured"
            ai_meta["duration_seconds"] = round(time.time() - t0, 2)
            return ai_meta

        ai_meta["ai_enabled"] = True

        # Initialize AI orchestrator and exploit generator
        orchestrator = MultiAIOrchestrator(llm_manager)
        exploit_gen = IntelligentExploitGenerator(llm_manager)

        ai_meta["consensus_config"] = {
            "threshold": orchestrator.config.threshold,
            "weights": orchestrator.config.weights,
            "timeout_seconds": orchestrator.config.timeout_seconds,
            "max_retries": orchestrator.config.max_retries,
            "fallback_enabled": orchestrator.config.fallback_enabled,
        }

        # ── AI Consensus on high-priority CVE findings ─────────────
        # Focus on UNVERIFIED results (most valuable for AI).
        # Skip promoted exploits (finding_type == "verified_exploit") — they
        # are already confirmed by real scanner evidence and don't need AI re-evaluation.
        priority_cves = [
            r
            for r in cve_results
            if r.get("verdict") in ("VULNERABLE_VERIFIED", "UNVERIFIED")
            and r.get("finding_type") != "verified_exploit"
        ][
            :10
        ]  # Cap to avoid excessive LLM calls

        ai_risk_assessments = []
        for cve_r in priority_cves:
            try:
                vuln = {
                    "id": cve_r.get("cve_id", ""),
                    "type": "cve",
                    "severity": cve_r.get("severity", "medium"),
                    "description": cve_r.get("description", ""),
                    "cvss_score": cve_r.get("cvss_score", 0),
                    "verdict": cve_r.get("verdict", "UNVERIFIED"),
                }
                context = {
                    "target_url": cve_r.get("target_url", ""),
                    "targets": target_urls,
                    "evidence": cve_r.get("evidence", {}),
                    "test_method": cve_r.get("test_method", ""),
                }
                # Get all 3 AI decisions in parallel
                architect, developer, lead = await asyncio.gather(
                    orchestrator.get_architect_decision(context, vuln),
                    orchestrator.get_developer_decision(context, vuln),
                    orchestrator.get_lead_decision(context, vuln),
                )
                # Compose consensus
                consensus = await orchestrator.compose_consensus(
                    architect, developer, lead, context
                )
                ai_risk_assessments.append(
                    {
                        "cve_id": cve_r.get("cve_id"),
                        "target": cve_r.get("target_url"),
                        "consensus_action": consensus.action,
                        "consensus_confidence": round(consensus.confidence, 3),
                        "consensus_reasoning": consensus.reasoning[:300],
                        "architect_confidence": round(architect.confidence, 3),
                        "developer_confidence": round(developer.confidence, 3),
                        "lead_confidence": round(lead.confidence, 3),
                        "execution_plan_steps": len(consensus.execution_plan),
                        "ai_generated": not consensus.metadata.get("fallback", False),
                    }
                )
                ai_meta["consensus_decisions"] += 1
            except Exception as e:
                logger.warning(
                    f"micro_pentest.ai_consensus_error cve={cve_r.get('cve_id')} error={e}"
                )

        ai_meta["ai_risk_assessments"] = ai_risk_assessments

        # ── AI Exploit Strategy Generation ─────────────────────────
        # Generate strategies for VULNERABLE CVEs (skip promoted exploits — already have PoCs)
        vuln_cves = [
            r
            for r in cve_results
            if r.get("verdict") == "VULNERABLE_VERIFIED"
            and r.get("finding_type") != "verified_exploit"
        ][:5]
        for cve_r in vuln_cves:
            try:
                from core.exploit_generator import PayloadComplexity

                vuln = {
                    "id": cve_r.get("cve_id", ""),
                    "type": cve_r.get("severity", "high"),
                    "description": cve_r.get("description", ""),
                }
                context = {
                    "target_url": cve_r.get("target_url", ""),
                    "evidence": cve_r.get("evidence", {}),
                }
                exploit = await exploit_gen.generate_exploit(
                    vuln, context, PayloadComplexity.ADVANCED
                )
                ai_meta["exploit_strategies_generated"] += 1
                ai_meta["ai_enhanced_findings"].append(
                    {
                        "cve_id": cve_r.get("cve_id"),
                        "exploit_type": exploit.exploit_type.value,
                        "complexity": exploit.complexity.value,
                        "success_probability": exploit.success_probability,
                        "evasion_techniques": exploit.evasion_techniques[:3],
                    }
                )
            except Exception as e:
                logger.warning(
                    f"micro_pentest.ai_exploit_gen_error cve={cve_r.get('cve_id')} error={e}"
                )

        # ── AI-Powered Findings Prioritization ─────────────────────
        # Ask GPT-4 to prioritize top general findings
        if findings:
            try:
                import json

                top_findings = findings[:15]
                findings_summary = json.dumps(
                    [
                        {
                            "title": f.get("title", f.get("type", "")),
                            "severity": f.get("severity", ""),
                            "target": f.get("target", ""),
                            "type": f.get("vulnerability_type", ""),
                        }
                        for f in top_findings
                    ],
                    indent=2,
                )

                prioritization_prompt = (
                    "You are a security analyst prioritizing vulnerability findings.\n\n"
                    f"Findings:\n{findings_summary}\n\n"
                    'Respond in JSON: {{"prioritized": [{{"title": ..., '
                    '"risk_rank": 1-10, "reasoning": ...}}]}}'
                )
                prioritization_response = await asyncio.wait_for(
                    asyncio.to_thread(
                        llm_manager.analyse,
                        "openai",
                        prompt=prioritization_prompt,
                        context={"targets": target_urls},
                        default_action="prioritize",
                        default_confidence=0.6,
                        default_reasoning="Findings prioritization",
                    ),
                    timeout=30,
                )
                if prioritization_response.metadata.get("mode") != "deterministic":
                    ai_meta["ai_findings_prioritization"] = {
                        "provider": "openai",
                        "confidence": round(prioritization_response.confidence, 3),
                        "ai_generated": True,
                    }
            except Exception as e:
                logger.warning(f"micro_pentest.ai_prioritization_error error={e}")

        # Collect orchestrator stats
        stats = orchestrator.get_statistics()
        ai_meta["total_llm_calls"] = stats.get("total_calls", 0)
        ai_meta["successful_llm_calls"] = stats.get("successful_calls", 0)
        ai_meta["fallback_llm_calls"] = stats.get("fallback_calls", 0)

    except ImportError as e:
        logger.warning(f"micro_pentest.ai_import_error error={e}")
        ai_meta["skip_reason"] = f"import_error: {e}"
    except Exception as e:
        logger.warning(f"micro_pentest.ai_analysis_error error={e}")
        ai_meta["error"] = str(e)

    ai_meta["duration_seconds"] = round(time.time() - t0, 2)
    return ai_meta


async def _run_builtin_vulnerability_scan(
    cve_ids: List[str],
    target_urls: List[str],
) -> MicroPentestResult:
    """Run AI-powered vulnerability scan with deterministic verification.

    Architecture:
    1. Deterministic Scanner — 4-stage verification + 19-phase general scan
    2. AI Analysis Layer — Multi-AI consensus (Gemini/Claude/GPT-4) for risk
       assessment, exploit strategy generation, and findings prioritization
    3. PentAGI Integration — Uses MultiAIOrchestrator and IntelligentExploitGenerator
    """
    try:
        from core.cve_tester import CVEVulnerabilityTester
        from core.real_scanner import get_real_vuln_scanner

        all_findings = []
        cve_results = []

        # Run CVE-specific tests
        cve_tester = CVEVulnerabilityTester(timeout=30.0, verify_ssl=False)
        cve_test_results = await cve_tester.test_multiple_cves(cve_ids, target_urls)

        for result in cve_test_results:
            cve_results.append(
                {
                    "cve_id": result.cve_id,
                    "target_url": result.target_url,
                    "vulnerable": result.vulnerable,
                    "confidence": result.confidence,
                    "severity": result.severity,
                    "cvss_score": result.cvss_score,
                    "description": result.description,
                    "remediation": result.remediation,
                    "test_method": result.test_method,
                    "evidence": result.evidence,
                    "verification_chain": getattr(result, "verification_chain", ""),
                    "verdict": getattr(result, "verdict", "UNVERIFIED"),
                    "applicability_score": getattr(result, "applicability_score", 0),
                    "test_coverage_score": getattr(result, "test_coverage_score", 0),
                    "confidence_score": getattr(result, "confidence_score", 0),
                    "how_to_verify": getattr(result, "how_to_verify", ""),
                }
            )

            if result.vulnerable:
                all_findings.append(
                    {
                        "type": "cve_vulnerability",
                        "cve_id": result.cve_id,
                        "target": result.target_url,
                        "severity": result.severity,
                        "confidence": result.confidence,
                        "description": result.description,
                    }
                )

        # Also run general vulnerability scan (async scan_url)
        # Import vuln intelligence for enrichment
        try:
            from core.vuln_intelligence import VULN_TYPE_INTEL
        except ImportError:
            VULN_TYPE_INTEL = {}

        scanner = get_real_vuln_scanner()
        for target_url in target_urls:
            try:
                real_findings = await scanner.scan_url(target_url)
                for rf in real_findings:
                    vtype_raw = str(getattr(rf, "vulnerability_type", ""))
                    vtype_key = _normalize_vuln_type(vtype_raw)
                    intel = VULN_TYPE_INTEL.get(vtype_key, {})
                    finding_dict = {
                        "type": "general_vuln_scan",
                        "target": target_url,
                        "title": getattr(rf, "title", "Unknown"),
                        "severity": getattr(rf, "severity", "unknown"),
                        "description": getattr(rf, "description", ""),
                        "vulnerability_type": vtype_raw,
                        "evidence": getattr(rf, "evidence", {}),
                        "remediation": getattr(rf, "remediation", ""),
                        "cwe_id": getattr(rf, "cwe_id", ""),
                        "cvss_score": getattr(rf, "cvss_score", 0.0),
                        "verified": getattr(rf, "verified", False),
                        "cve_ids": cve_ids,
                        # Vulnerability intelligence enrichment
                        "source_file": intel.get("source_file", ""),
                        "source_function": intel.get("source_function", ""),
                        "source_lines": intel.get("source_lines", ""),
                        "detection_logic": intel.get("detection_logic", ""),
                        "threat_scenario": intel.get("threat_scenario", ""),
                        "threat_actor": intel.get("threat_actor", ""),
                        "attack_complexity": intel.get("attack_complexity", ""),
                        "business_impact": intel.get("business_impact", []),
                        "owasp_top10": intel.get("owasp_top10", ""),
                        "stride": intel.get("stride", ""),
                        "real_world_examples": intel.get("real_world_examples", []),
                        "os_relevance": intel.get("os_relevance", ""),
                        "remediation_priority": intel.get("remediation_priority", ""),
                        "manual_test": intel.get("manual_test", ""),
                    }
                    all_findings.append(finding_dict)
            except Exception as scan_error:
                logger.warning(
                    f"micro_pentest.target_scan_error target={target_url} error={scan_error}"
                )

        # ── Extract architecture profiles from scanner ──────────────────
        architecture_profiles = {}
        for target_url in target_urls:
            if target_url in scanner.architecture_profiles:
                architecture_profiles[target_url] = scanner.architecture_profiles[
                    target_url
                ].to_dict()

        # Generate a tracking flow_id
        import random

        flow_id = random.randint(100000, 999999)

        # ── De-duplicate general findings ──────────────────────────────
        all_findings = _deduplicate_findings(all_findings)

        # ── Promote exploitable general findings to VULNERABLE_VERIFIED ─
        # Real exploits (CORS, host injection, open redirect, etc.) with
        # evidence are promoted to cve_results so they appear as confirmed
        # vulnerabilities — not just "informational" general findings.
        verified_exploits = _promote_exploitable_findings(all_findings)
        if verified_exploits:
            logger.info(
                f"micro_pentest.promoted_exploits count={len(verified_exploits)} "
                f"types={[e['cve_id'] for e in verified_exploits]}"
            )
            # Prepend so they appear first in the report
            cve_results = verified_exploits + cve_results

        # ── Verdict-aware counts ──────────────────────────────────────
        confirmed_vuln = [
            r for r in cve_results if r.get("verdict") == "VULNERABLE_VERIFIED"
        ]
        unverified = [r for r in cve_results if r.get("verdict") == "UNVERIFIED"]
        not_applicable = [
            r for r in cve_results if r.get("verdict") == "NOT_APPLICABLE"
        ]
        verified_safe = [
            r for r in cve_results if r.get("verdict") == "NOT_VULNERABLE_VERIFIED"
        ]

        # --- Advanced Analysis ---
        mitre_techniques = _map_findings_to_mitre(all_findings, cve_results)
        attack_chains = _build_attack_chains(
            all_findings, cve_results, mitre_techniques
        )
        compliance = _validate_compliance(all_findings, cve_results)
        risk = _compute_risk_score(all_findings, cve_results, attack_chains, compliance)
        poc_commands = _generate_poc_commands(cve_results, all_findings)
        fp_analysis = _filter_false_positives(cve_results, all_findings)
        executive_summary = _generate_executive_summary(
            cve_results, all_findings, mitre_techniques, attack_chains, compliance, risk
        )

        # ── AI-Powered Analysis Layer (PentAGI) ───────────────────
        logger.info("micro_pentest.ai_analysis_start")
        ai_analysis = await _run_ai_analysis(cve_results, all_findings, target_urls)
        ai_enabled = ai_analysis.get("ai_enabled", False)
        logger.info(
            f"micro_pentest.ai_analysis_complete ai_enabled={ai_enabled} "
            f"consensus_decisions={ai_analysis.get('consensus_decisions', 0)} "
            f"duration={ai_analysis.get('duration_seconds', 0)}s"
        )

        # Engine label reflects actual capabilities used
        engine_label = (
            "aldeci_pentagi_ai_v1" if ai_enabled else "aldeci_deterministic_v3"
        )

        # Build scan metadata
        scan_metadata = {
            "engine": engine_label,
            "mpte_available": ai_enabled,
            "ai_powered": ai_enabled,
            "ai_analysis": ai_analysis,
            "total_cve_tests": len(cve_results),
            "total_targets": len(target_urls),
            "total_findings": len(all_findings),
            "cve_tests_registered": len(cve_ids),
            "scan_phases": 19,
            "verification_stages": 4,
            "verdict_counts": {
                "confirmed_vulnerable": len(confirmed_vuln),
                "verified_safe": len(verified_safe),
                "not_applicable": len(not_applicable),
                "unverified": len(unverified),
            },
            "mitre_techniques": mitre_techniques,
            "attack_chains": attack_chains,
            "compliance": compliance,
            "risk_score": risk,
            "poc_commands": poc_commands,
            "false_positive_analysis": fp_analysis,
            "executive_summary": executive_summary,
            "architecture_profiles": architecture_profiles,
        }

        ai_suffix = ""
        if ai_enabled:
            ai_suffix = f" | AI: {ai_analysis.get('consensus_decisions', 0)} consensus, {ai_analysis.get('exploit_strategies_generated', 0)} exploits"

        return MicroPentestResult(
            status="completed",
            flow_id=flow_id,
            cve_ids=cve_ids,
            target_urls=target_urls,
            message=(
                f"Scan complete: {len(confirmed_vuln)} confirmed vulnerable, "
                f"{len(verified_safe)} verified safe, "
                f"{len(not_applicable)} not applicable, "
                f"{len(unverified)} unverified, "
                f"{len(all_findings)} findings — "
                f"Risk {risk['level'].upper()} ({risk['score']}/10)"
                f"{ai_suffix}"
            ),
            cve_results=cve_results,
            findings=all_findings,
            scan_metadata=scan_metadata,
        )

    except ImportError as ie:
        logger.error(f"micro_pentest.scanner_import_error error={ie}")
        return MicroPentestResult(
            status="error",
            cve_ids=cve_ids,
            target_urls=target_urls,
            error="Built-in scanner not available and MPTE unreachable",
        )
    except Exception as e:
        logger.error(f"micro_pentest.builtin_scan_error error={e}")
        return MicroPentestResult(
            status="error",
            cve_ids=cve_ids,
            target_urls=target_urls,
            error=f"Built-in scan failed: {str(e)}",
        )


async def get_micro_pentest_status(
    flow_id: int,
    config: Optional[MicroPentestConfig] = None,
) -> MicroPentestStatus:
    """Get status of a micro penetration test flow.

    Args:
        flow_id: The MPTE flow ID
        config: Optional configuration (uses defaults if not provided)

    Returns:
        MicroPentestStatus with current status and progress
    """
    if config is None:
        config = MicroPentestConfig()

    try:
        async with _get_mpte_client(config) as client:
            response = await client.get(f"/api/v1/flows/{flow_id}")

            if response.status_code != 200:
                return MicroPentestStatus(
                    flow_id=flow_id,
                    status="error",
                    error=f"Failed to get flow status: {response.text}",
                )

            flow_data = response.json()
            return MicroPentestStatus(
                flow_id=flow_id,
                status=flow_data.get("status", "unknown"),
                progress=flow_data.get("progress", 0),
                tasks=flow_data.get("tasks", []),
            )

    except httpx.RequestError as e:
        logger.error(f"micro_pentest.status_error flow_id={flow_id} error={e}")
        return MicroPentestStatus(
            flow_id=flow_id,
            status="error",
            error="Failed to connect to MPTE",
        )


@dataclass
class BatchTestConfig:
    """Configuration for a single test in a batch."""

    cve_ids: List[str] = field(default_factory=list)
    target_urls: List[str] = field(default_factory=list)
    context: Dict[str, Any] = field(default_factory=dict)


async def run_batch_micro_pentests(
    test_configs: List[BatchTestConfig],
    config: Optional[MicroPentestConfig] = None,
) -> Dict[str, Any]:
    """Run multiple micro penetration tests in parallel.

    Args:
        test_configs: List of test configurations
        config: Optional configuration (uses defaults if not provided)

    Returns:
        Dictionary with batch results
    """
    if config is None:
        config = MicroPentestConfig()

    if not test_configs:
        return {
            "status": "error",
            "error": "At least one test configuration is required",
            "total": 0,
            "successful": 0,
            "failed": 0,
            "results": [],
        }

    logger.info(f"micro_pentest.batch_start count={len(test_configs)}")

    # Run tests in parallel
    tasks = [
        run_micro_pentest(
            cve_ids=tc.cve_ids,
            target_urls=tc.target_urls,
            context=tc.context,
            config=config,
        )
        for tc in test_configs
    ]

    results = await asyncio.gather(*tasks, return_exceptions=True)

    successful = [
        r
        for r in results
        if isinstance(r, MicroPentestResult) and r.status == "started"
    ]
    failed = [
        r
        for r in results
        if isinstance(r, Exception)
        or (isinstance(r, MicroPentestResult) and r.status == "error")
    ]

    return {
        "status": "completed",
        "total": len(test_configs),
        "successful": len(successful),
        "failed": len(failed),
        "results": [
            r.to_dict()
            if isinstance(r, MicroPentestResult)
            else {"status": "error", "error": str(r)}
            for r in results
        ],
    }


__all__ = [
    "MicroPentestConfig",
    "MicroPentestResult",
    "MicroPentestStatus",
    "BatchTestConfig",
    "run_micro_pentest",
    "get_micro_pentest_status",
    "run_batch_micro_pentests",
]
