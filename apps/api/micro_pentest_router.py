"""API router for micro penetration tests using PentAGI integration.

This router provides endpoints for running micro penetration tests against
specific CVEs and target URLs using the PentAGI service.
"""

from __future__ import annotations

from typing import Any, Dict, List, Optional

from fastapi import APIRouter, HTTPException, status
from pydantic import BaseModel, Field

from core.micro_pentest import (
    BatchTestConfig,
    get_micro_pentest_status,
    run_batch_micro_pentests,
    run_micro_pentest,
)

router = APIRouter(prefix="/api/v1/micro-pentest", tags=["micro-pentest"])


class RunMicroPentestRequest(BaseModel):
    """Request model for running a micro penetration test."""

    cve_ids: List[str] = Field(..., description="List of CVE IDs to test")
    target_urls: List[str] = Field(
        ..., description="List of target URLs to test against"
    )
    context: Optional[Dict[str, Any]] = Field(
        default=None, description="Optional context information for the test"
    )


class RunMicroPentestResponse(BaseModel):
    """Response model for a micro penetration test."""

    status: str = Field(..., description="Status of the test (started, error)")
    flow_id: Optional[int] = Field(
        default=None, description="PentAGI flow ID if started"
    )
    cve_ids: List[str] = Field(default_factory=list, description="CVE IDs being tested")
    target_urls: List[str] = Field(
        default_factory=list, description="Target URLs being tested"
    )
    message: str = Field(default="", description="Status message")
    error: Optional[str] = Field(default=None, description="Error message if failed")


class MicroPentestStatusResponse(BaseModel):
    """Response model for micro penetration test status."""

    flow_id: int = Field(..., description="PentAGI flow ID")
    status: str = Field(..., description="Current status of the test")
    progress: int = Field(default=0, description="Progress percentage (0-100)")
    tasks: List[Dict[str, Any]] = Field(
        default_factory=list, description="List of tasks"
    )
    error: Optional[str] = Field(default=None, description="Error message if failed")


class BatchTestConfigModel(BaseModel):
    """Configuration for a single test in a batch."""

    cve_ids: List[str] = Field(default_factory=list, description="CVE IDs to test")
    target_urls: List[str] = Field(
        default_factory=list, description="Target URLs to test"
    )
    context: Dict[str, Any] = Field(
        default_factory=dict, description="Optional context"
    )


class BatchMicroPentestRequest(BaseModel):
    """Request model for running batch micro penetration tests."""

    test_configs: List[BatchTestConfigModel] = Field(
        ..., description="List of test configurations"
    )


class BatchMicroPentestResponse(BaseModel):
    """Response model for batch micro penetration tests."""

    status: str = Field(..., description="Overall batch status")
    total: int = Field(..., description="Total number of tests")
    successful: int = Field(..., description="Number of successful tests")
    failed: int = Field(..., description="Number of failed tests")
    results: List[Dict[str, Any]] = Field(
        default_factory=list, description="Individual results"
    )
    error: Optional[str] = Field(
        default=None, description="Error message if batch failed"
    )


@router.post(
    "/run", response_model=RunMicroPentestResponse, status_code=status.HTTP_201_CREATED
)
async def run_pentest(request: RunMicroPentestRequest) -> Dict[str, Any]:
    """Run micro penetration tests for selected CVEs using PentAGI.

    This endpoint initiates a micro penetration test flow in PentAGI to verify
    the exploitability of specified CVEs against target URLs.

    Args:
        request: The test request containing CVE IDs and target URLs

    Returns:
        Response with flow_id if successful, or error details if failed

    Raises:
        HTTPException: If validation fails or PentAGI is unavailable
    """
    if not request.cve_ids:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="At least one CVE ID is required",
        )

    if not request.target_urls:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="At least one target URL is required",
        )

    result = await run_micro_pentest(
        cve_ids=request.cve_ids,
        target_urls=request.target_urls,
        context=request.context,
    )

    if result.status == "error":
        raise HTTPException(
            status_code=status.HTTP_502_BAD_GATEWAY,
            detail=result.error or "Failed to start micro penetration test",
        )

    return result.to_dict()


@router.get("/status/{flow_id}", response_model=MicroPentestStatusResponse)
async def get_pentest_status(flow_id: int) -> Dict[str, Any]:
    """Get status of a micro penetration test flow.

    Args:
        flow_id: The PentAGI flow ID

    Returns:
        Current status and progress of the test

    Raises:
        HTTPException: If flow not found or PentAGI is unavailable
    """
    result = await get_micro_pentest_status(flow_id)

    if result.status == "error":
        raise HTTPException(
            status_code=status.HTTP_502_BAD_GATEWAY,
            detail=result.error or "Failed to get flow status",
        )

    return result.to_dict()


@router.post(
    "/batch",
    response_model=BatchMicroPentestResponse,
    status_code=status.HTTP_201_CREATED,
)
async def run_batch_pentests(request: BatchMicroPentestRequest) -> Dict[str, Any]:
    """Run multiple micro penetration tests in parallel.

    This endpoint allows running multiple micro penetration tests concurrently,
    each with its own set of CVE IDs and target URLs.

    Args:
        request: The batch request containing multiple test configurations

    Returns:
        Batch results with individual test outcomes

    Raises:
        HTTPException: If validation fails
    """
    if not request.test_configs:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="At least one test configuration is required",
        )

    # Convert Pydantic models to dataclasses
    configs = [
        BatchTestConfig(
            cve_ids=tc.cve_ids,
            target_urls=tc.target_urls,
            context=tc.context,
        )
        for tc in request.test_configs
    ]

    result = await run_batch_micro_pentests(configs)

    if result.get("status") == "error" and result.get("total", 0) == 0:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=result.get("error", "Batch test failed"),
        )

    return result


__all__ = ["router"]
