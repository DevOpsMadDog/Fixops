"""Tests for micro penetration test API router."""
import asyncio
from unittest.mock import AsyncMock, patch

import pytest
from fastapi import FastAPI
from fastapi.testclient import TestClient

from apps.api.micro_pentest_router import (
    AttackSurface,
    AttackVector,
    ComplianceFramework,
    MicroPentestEngine,
    MicroScanConfig,
    MicroScanStatus,
    ScanMode,
    ThreatCategory,
    ThreatModel,
    router,
)
from core.micro_pentest import MicroPentestResult, MicroPentestStatus


@pytest.fixture
def app():
    """Create test FastAPI app with router."""
    app = FastAPI()
    app.include_router(router)
    return app


@pytest.fixture
def client(app):
    """Create test client."""
    return TestClient(app)


class TestRunPentestEndpoint:
    """Tests for POST /api/v1/micro-pentest/run endpoint."""

    def test_empty_cve_ids(self, client):
        """Test validation error when cve_ids is empty."""
        response = client.post(
            "/api/v1/micro-pentest/run",
            json={"cve_ids": [], "target_urls": ["http://example.com"]},
        )
        assert response.status_code == 400
        assert "At least one CVE ID is required" in response.json()["detail"]

    def test_empty_target_urls(self, client):
        """Test validation error when target_urls is empty."""
        response = client.post(
            "/api/v1/micro-pentest/run",
            json={"cve_ids": ["CVE-2024-1234"], "target_urls": []},
        )
        assert response.status_code == 400
        assert "At least one target URL is required" in response.json()["detail"]

    def test_successful_run(self, client):
        """Test successful micro pentest run."""
        mock_result = MicroPentestResult(
            status="started",
            flow_id=12345,
            cve_ids=["CVE-2024-1234"],
            target_urls=["http://example.com"],
            message="Micro penetration test started for 1 CVEs",
        )

        with patch(
            "apps.api.micro_pentest_router.run_micro_pentest",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            response = client.post(
                "/api/v1/micro-pentest/run",
                json={
                    "cve_ids": ["CVE-2024-1234"],
                    "target_urls": ["http://example.com"],
                },
            )

        assert response.status_code == 201
        data = response.json()
        assert data["status"] == "started"
        assert data["flow_id"] == 12345

    def test_successful_run_with_context(self, client):
        """Test successful run with context."""
        mock_result = MicroPentestResult(
            status="started",
            flow_id=99999,
            cve_ids=["CVE-2024-1234"],
            target_urls=["http://example.com"],
            message="Test started",
        )

        with patch(
            "apps.api.micro_pentest_router.run_micro_pentest",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            response = client.post(
                "/api/v1/micro-pentest/run",
                json={
                    "cve_ids": ["CVE-2024-1234"],
                    "target_urls": ["http://example.com"],
                    "context": {"environment": "staging"},
                },
            )

        assert response.status_code == 201

    def test_pentagi_error(self, client):
        """Test handling of PentAGI error."""
        mock_result = MicroPentestResult(
            status="error",
            error="PentAGI service unavailable",
        )

        with patch(
            "apps.api.micro_pentest_router.run_micro_pentest",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            response = client.post(
                "/api/v1/micro-pentest/run",
                json={
                    "cve_ids": ["CVE-2024-1234"],
                    "target_urls": ["http://example.com"],
                },
            )

        assert response.status_code == 503
        assert "PentAGI service unavailable" in response.json()["detail"]

    def test_pentagi_error_no_message(self, client):
        """Test handling of PentAGI error without error message."""
        mock_result = MicroPentestResult(
            status="error",
            error=None,
        )

        with patch(
            "apps.api.micro_pentest_router.run_micro_pentest",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            response = client.post(
                "/api/v1/micro-pentest/run",
                json={
                    "cve_ids": ["CVE-2024-1234"],
                    "target_urls": ["http://example.com"],
                },
            )

        assert response.status_code == 503
        assert "Failed to start micro penetration test" in response.json()["detail"]


class TestGetPentestStatusEndpoint:
    """Tests for GET /api/v1/micro-pentest/status/{flow_id} endpoint."""

    def test_successful_status(self, client):
        """Test successful status retrieval."""
        mock_status = MicroPentestStatus(
            flow_id=123,
            status="running",
            progress=50,
            tasks=[{"id": 1, "name": "scan"}],
        )

        with patch(
            "apps.api.micro_pentest_router.get_micro_pentest_status",
            new_callable=AsyncMock,
            return_value=mock_status,
        ):
            response = client.get("/api/v1/micro-pentest/status/123")

        assert response.status_code == 200
        data = response.json()
        assert data["flow_id"] == 123
        assert data["status"] == "running"
        assert data["progress"] == 50

    def test_status_error(self, client):
        """Test handling of status error."""
        mock_status = MicroPentestStatus(
            flow_id=999,
            status="error",
            error="Flow not found",
        )

        with patch(
            "apps.api.micro_pentest_router.get_micro_pentest_status",
            new_callable=AsyncMock,
            return_value=mock_status,
        ):
            response = client.get("/api/v1/micro-pentest/status/999")

        assert response.status_code == 503
        assert "Flow not found" in response.json()["detail"]

    def test_status_error_no_message(self, client):
        """Test handling of status error without error message."""
        mock_status = MicroPentestStatus(
            flow_id=999,
            status="error",
            error=None,
        )

        with patch(
            "apps.api.micro_pentest_router.get_micro_pentest_status",
            new_callable=AsyncMock,
            return_value=mock_status,
        ):
            response = client.get("/api/v1/micro-pentest/status/999")

        assert response.status_code == 503
        assert "Failed to get flow status" in response.json()["detail"]


class TestBatchPentestsEndpoint:
    """Tests for POST /api/v1/micro-pentest/batch endpoint."""

    def test_empty_configs(self, client):
        """Test validation error when test_configs is empty."""
        response = client.post(
            "/api/v1/micro-pentest/batch",
            json={"test_configs": []},
        )
        assert response.status_code == 400
        assert (
            "At least one test configuration is required" in response.json()["detail"]
        )

    def test_successful_batch(self, client):
        """Test successful batch execution."""
        mock_result = {
            "status": "completed",
            "total": 2,
            "successful": 2,
            "failed": 0,
            "results": [
                {"status": "started", "flow_id": 1},
                {"status": "started", "flow_id": 2},
            ],
        }

        with patch(
            "apps.api.micro_pentest_router.run_batch_micro_pentests",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            response = client.post(
                "/api/v1/micro-pentest/batch",
                json={
                    "test_configs": [
                        {
                            "cve_ids": ["CVE-2024-1234"],
                            "target_urls": ["http://example.com"],
                        },
                        {
                            "cve_ids": ["CVE-2024-5678"],
                            "target_urls": ["http://test.com"],
                        },
                    ]
                },
            )

        assert response.status_code == 201
        data = response.json()
        assert data["status"] == "completed"
        assert data["total"] == 2
        assert data["successful"] == 2

    def test_batch_with_context(self, client):
        """Test batch with context in configs."""
        mock_result = {
            "status": "completed",
            "total": 1,
            "successful": 1,
            "failed": 0,
            "results": [{"status": "started", "flow_id": 1}],
        }

        with patch(
            "apps.api.micro_pentest_router.run_batch_micro_pentests",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            response = client.post(
                "/api/v1/micro-pentest/batch",
                json={
                    "test_configs": [
                        {
                            "cve_ids": ["CVE-2024-1234"],
                            "target_urls": ["http://example.com"],
                            "context": {"env": "test"},
                        },
                    ]
                },
            )

        assert response.status_code == 201

    def test_batch_error_empty_config_response(self, client):
        """Test router's defensive handling when batch runner returns error dict.

        Note: This tests the router's error handling branch for when the core
        function returns status="error" with total=0. In practice, this only
        occurs when test_configs is empty (already validated by the router),
        but we test the defensive branch to ensure proper error propagation.
        """
        mock_result = {
            "status": "error",
            "total": 0,
            "successful": 0,
            "failed": 0,
            "error": "At least one test configuration is required",
        }

        with patch(
            "apps.api.micro_pentest_router.run_batch_micro_pentests",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            response = client.post(
                "/api/v1/micro-pentest/batch",
                json={
                    "test_configs": [
                        {
                            "cve_ids": ["CVE-2024-1234"],
                            "target_urls": ["http://example.com"],
                        },
                    ]
                },
            )

        assert response.status_code == 400
        assert (
            "At least one test configuration is required" in response.json()["detail"]
        )

    def test_batch_error_no_message(self, client):
        """Test router's defensive handling when batch returns error without message.

        Note: Tests the fallback error message when the core function returns
        an error dict without an explicit error message.
        """
        mock_result = {
            "status": "error",
            "total": 0,
            "successful": 0,
            "failed": 0,
        }

        with patch(
            "apps.api.micro_pentest_router.run_batch_micro_pentests",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            response = client.post(
                "/api/v1/micro-pentest/batch",
                json={
                    "test_configs": [
                        {
                            "cve_ids": ["CVE-2024-1234"],
                            "target_urls": ["http://example.com"],
                        },
                    ]
                },
            )

        assert response.status_code == 400
        assert "Batch test failed" in response.json()["detail"]

    def test_batch_partial_success(self, client):
        """Test batch with partial success (some tests succeed, some fail)."""
        mock_result = {
            "status": "completed",
            "total": 2,
            "successful": 1,
            "failed": 1,
            "results": [
                {"status": "started", "flow_id": 1},
                {"status": "error", "error": "Failed"},
            ],
        }

        with patch(
            "apps.api.micro_pentest_router.run_batch_micro_pentests",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            response = client.post(
                "/api/v1/micro-pentest/batch",
                json={
                    "test_configs": [
                        {
                            "cve_ids": ["CVE-2024-1234"],
                            "target_urls": ["http://example.com"],
                        },
                        {
                            "cve_ids": ["CVE-2024-5678"],
                            "target_urls": ["http://test.com"],
                        },
                    ]
                },
            )

        assert response.status_code == 201
        data = response.json()
        assert data["status"] == "completed"
        assert data["successful"] == 1
        assert data["failed"] == 1

    def test_batch_all_tests_failed(self, client):
        """Test batch where all individual tests failed returns 503."""
        mock_result = {
            "status": "completed",
            "total": 2,
            "successful": 0,
            "failed": 2,
            "results": [
                {"status": "error", "error": "PentAGI unavailable"},
                {"status": "error", "error": "PentAGI unavailable"},
            ],
        }

        with patch(
            "apps.api.micro_pentest_router.run_batch_micro_pentests",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            response = client.post(
                "/api/v1/micro-pentest/batch",
                json={
                    "test_configs": [
                        {
                            "cve_ids": ["CVE-2024-1234"],
                            "target_urls": ["http://example.com"],
                        },
                        {
                            "cve_ids": ["CVE-2024-5678"],
                            "target_urls": ["http://test.com"],
                        },
                    ]
                },
            )

        assert response.status_code == 503
        assert "All micro penetration tests failed" in response.json()["detail"]


class TestEnterpriseEndpoints:
    """Tests for enterprise micro pentest API endpoints."""

    def test_cancel_enterprise_scan_success(self, client):
        """Test successful cancel of enterprise scan (covers line 1141)."""
        # Mock the enterprise_engine.cancel_scan to return True
        with patch(
            "apps.api.micro_pentest_router.enterprise_engine.cancel_scan",
            new_callable=AsyncMock,
            return_value=True,
        ):
            response = client.post(
                "/api/v1/micro-pentest/enterprise/scan/test-scan-id/cancel"
            )
            assert response.status_code == 200
            data = response.json()
            assert data["status"] == "cancelled"
            assert data["scan_id"] == "test-scan-id"

    def test_run_enterprise_scan(self, client):
        """Test running an enterprise scan."""
        response = client.post(
            "/api/v1/micro-pentest/enterprise/scan",
            json={
                "name": "Test Scan",
                "attack_surface": {
                    "name": "Test API",
                    "target_url": "https://api.example.com",
                    "target_type": "api",
                    "endpoints": ["/api/v1/users", "/api/v1/auth"],
                    "authentication_required": True,
                    "authentication_type": "jwt",
                    "technologies": ["python", "fastapi"],
                    "environment": "staging",
                },
                "threat_model": {
                    "name": "API Security Test",
                    "description": "Test for common API vulnerabilities",
                    "categories": ["initial_access", "credential_access"],
                    "attack_vectors": [
                        "sql_injection",
                        "xss",
                        "authentication_bypass",
                        "api_abuse",
                    ],
                    "compliance_frameworks": ["soc2", "owasp_top_10"],
                    "priority": 8,
                },
                "scan_mode": "active",
                "timeout_seconds": 60,
                "stop_on_critical": False,
                "include_proof_of_concept": True,
                "tenant_id": "test-tenant",
                "organization_id": "test-org",
                "tags": ["test", "ci"],
            },
        )
        assert response.status_code == 201
        data = response.json()
        assert "scan_id" in data
        assert data["status"] == "completed"

    def test_run_enterprise_scan_with_invalid_enums(self, client):
        """Test running an enterprise scan with invalid enum values."""
        response = client.post(
            "/api/v1/micro-pentest/enterprise/scan",
            json={
                "name": "Test Scan",
                "attack_surface": {
                    "name": "Test API",
                    "target_url": "https://api.example.com",
                    "target_type": "api",
                    "endpoints": [],
                    "authentication_required": False,
                    "technologies": [],
                    "environment": "test",
                },
                "threat_model": {
                    "name": "Test",
                    "description": "Test",
                    "categories": ["invalid_category"],
                    "attack_vectors": ["invalid_vector"],
                    "compliance_frameworks": ["invalid_framework"],
                    "priority": 5,
                },
                "scan_mode": "invalid_mode",
                "timeout_seconds": 30,
                "stop_on_critical": False,
                "include_proof_of_concept": False,
                "tenant_id": "test",
                "organization_id": "test",
                "tags": [],
            },
        )
        # Should still succeed with defaults for invalid enums
        assert response.status_code == 201

    def test_get_enterprise_scan_result_not_found(self, client):
        """Test getting a non-existent scan result."""
        response = client.get("/api/v1/micro-pentest/enterprise/scan/non-existent-id")
        assert response.status_code == 404
        assert "not found" in response.json()["detail"]

    def test_list_enterprise_scans(self, client):
        """Test listing enterprise scans."""
        response = client.get("/api/v1/micro-pentest/enterprise/scans")
        assert response.status_code == 200
        data = response.json()
        assert "scans" in data
        assert "total" in data

    def test_list_enterprise_scans_with_filters(self, client):
        """Test listing enterprise scans with filters."""
        response = client.get(
            "/api/v1/micro-pentest/enterprise/scans",
            params={
                "tenant_id": "test-tenant",
                "organization_id": "test-org",
                "scan_status": "completed",
            },
        )
        assert response.status_code == 200

    def test_list_enterprise_scans_with_invalid_status(self, client):
        """Test listing enterprise scans with invalid status filter."""
        response = client.get(
            "/api/v1/micro-pentest/enterprise/scans",
            params={"scan_status": "invalid_status"},
        )
        # Should still succeed, invalid status is ignored
        assert response.status_code == 200

    def test_cancel_enterprise_scan_not_found(self, client):
        """Test canceling a non-existent scan."""
        response = client.post(
            "/api/v1/micro-pentest/enterprise/scan/non-existent-id/cancel"
        )
        assert response.status_code == 404
        assert "not found" in response.json()["detail"]

    def test_get_audit_logs(self, client):
        """Test getting audit logs."""
        response = client.get("/api/v1/micro-pentest/enterprise/audit-logs")
        assert response.status_code == 200
        data = response.json()
        assert "logs" in data
        assert "total" in data

    def test_get_audit_logs_with_filters(self, client):
        """Test getting audit logs with filters."""
        response = client.get(
            "/api/v1/micro-pentest/enterprise/audit-logs",
            params={
                "tenant_id": "test-tenant",
                "organization_id": "test-org",
                "user_id": "test-user",
                "action": "start_micro_scan",
                "limit": 50,
            },
        )
        assert response.status_code == 200

    def test_get_engine_health(self, client):
        """Test getting engine health status."""
        response = client.get("/api/v1/micro-pentest/enterprise/health")
        assert response.status_code == 200
        data = response.json()
        assert data["status"] == "healthy"
        assert "active_scans" in data
        assert "total_scans" in data

    def test_list_attack_vectors(self, client):
        """Test listing attack vectors."""
        response = client.get("/api/v1/micro-pentest/enterprise/attack-vectors")
        assert response.status_code == 200
        data = response.json()
        assert "attack_vectors" in data
        assert "total" in data
        assert data["total"] > 0

    def test_list_threat_categories(self, client):
        """Test listing threat categories."""
        response = client.get("/api/v1/micro-pentest/enterprise/threat-categories")
        assert response.status_code == 200
        data = response.json()
        assert "threat_categories" in data
        assert "total" in data
        assert data["total"] > 0

    def test_list_compliance_frameworks(self, client):
        """Test listing compliance frameworks."""
        response = client.get("/api/v1/micro-pentest/enterprise/compliance-frameworks")
        assert response.status_code == 200
        data = response.json()
        assert "compliance_frameworks" in data
        assert "total" in data
        assert data["total"] > 0

    def test_list_scan_modes(self, client):
        """Test listing scan modes."""
        response = client.get("/api/v1/micro-pentest/enterprise/scan-modes")
        assert response.status_code == 200
        data = response.json()
        assert "scan_modes" in data
        assert "total" in data
        assert data["total"] > 0


class TestMicroPentestEngineDirectCoverage:
    """Direct tests for MicroPentestEngine to cover edge cases."""

    def test_engine_scan_exception_handling(self):
        """Test that scan exceptions are handled properly (covers lines 442-445)."""
        engine = MicroPentestEngine(enable_audit_logging=False)

        # Create a config that will be used
        attack_surface = AttackSurface(
            name="Test",
            target_url="https://test.com",
            target_type="api",
            endpoints=["/api"],
            authentication_required=False,
            authentication_type="none",
            technologies=["python"],
            environment="test",
        )
        threat_model = ThreatModel(
            name="Test",
            description="Test",
            categories=[ThreatCategory.INITIAL_ACCESS],
            attack_vectors=[AttackVector.SQL_INJECTION],
            compliance_frameworks=[ComplianceFramework.SOC2],
            priority=5,
        )
        config = MicroScanConfig(
            name="Test Scan",
            attack_surface=attack_surface,
            threat_model=threat_model,
            scan_mode=ScanMode.PASSIVE,
            timeout_seconds=30,
            stop_on_critical=False,
            include_proof_of_concept=False,
            tenant_id="test",
            organization_id="test",
            tags=[],
            created_by="test",
        )

        # Mock _run_vulnerability_scan to raise an exception
        async def run_test():
            with patch.object(
                engine, "_run_vulnerability_scan", side_effect=Exception("Test error")
            ):
                result = await engine.run_scan(config)
                # Verify the scan failed properly
                assert result.status == MicroScanStatus.FAILED
                return result

        loop = asyncio.new_event_loop()
        try:
            result = loop.run_until_complete(run_test())
            assert result.status == MicroScanStatus.FAILED
        finally:
            loop.close()

    def test_engine_cancel_active_scan(self):
        """Test cancelling an active scan (covers lines 696-699)."""
        engine = MicroPentestEngine(enable_audit_logging=False)

        # Manually add a scan to active scans to simulate a running scan
        scan_id = "test-cancel-scan-123"
        engine._active_scans[scan_id] = True

        # Create a mock scan result
        attack_surface = AttackSurface(
            name="Test",
            target_url="https://test.com",
            target_type="api",
            endpoints=["/api"],
            authentication_required=False,
            authentication_type="none",
            technologies=["python"],
            environment="test",
        )
        threat_model = ThreatModel(
            name="Test",
            description="Test",
            categories=[ThreatCategory.INITIAL_ACCESS],
            attack_vectors=[AttackVector.SQL_INJECTION],
            compliance_frameworks=[ComplianceFramework.SOC2],
            priority=5,
        )
        config = MicroScanConfig(
            name="Test Scan",
            attack_surface=attack_surface,
            threat_model=threat_model,
            scan_mode=ScanMode.PASSIVE,
            timeout_seconds=30,
            stop_on_critical=False,
            include_proof_of_concept=False,
            tenant_id="test",
            organization_id="test",
            tags=[],
            created_by="test",
        )

        from apps.api.micro_pentest_router import MicroScanResult

        engine._scans[scan_id] = MicroScanResult(
            scan_id=scan_id,
            config=config,
            status=MicroScanStatus.RUNNING,
        )

        async def run_cancel():
            result = await engine.cancel_scan(scan_id)
            return result

        loop = asyncio.new_event_loop()
        try:
            result = loop.run_until_complete(run_cancel())
            assert result is True
            assert engine._scans[scan_id].status == MicroScanStatus.CANCELLED
        finally:
            loop.close()

    def test_compliance_validation_else_branch(self):
        """Test compliance validation with frameworks that hit the else branch (covers line 583)."""
        engine = MicroPentestEngine(enable_audit_logging=False)

        # Create findings with no critical/high issues
        findings = []

        # Test with ISO27001, NIST_800_53, and CIS which should hit the else branch
        frameworks = [
            ComplianceFramework.ISO27001,
            ComplianceFramework.NIST_800_53,
            ComplianceFramework.CIS,
        ]

        async def run_validation():
            result = await engine._validate_compliance(frameworks, findings)
            return result

        loop = asyncio.new_event_loop()
        try:
            result = loop.run_until_complete(run_validation())
            # These frameworks should be in the result and pass (no critical/high findings)
            assert "iso27001" in result
            assert "nist_800_53" in result
            assert "cis" in result
            assert result["iso27001"] is True
            assert result["nist_800_53"] is True
            assert result["cis"] is True
        finally:
            loop.close()


class TestMicroPentestEngineCoverage:
    """Tests for additional MicroPentestEngine coverage."""

    def test_cancel_running_scan(self, client):
        """Test cancelling a running scan successfully (covers lines 696-699, 1141)."""
        # First create a scan
        create_response = client.post(
            "/api/v1/micro-pentest/enterprise/scan",
            json={
                "name": "Scan to Cancel",
                "attack_surface": {
                    "name": "Test API",
                    "target_url": "https://api.example.com",
                    "target_type": "api",
                    "endpoints": ["/api/v1/users"],
                    "authentication_required": False,
                    "authentication_type": "none",
                    "technologies": ["python"],
                    "environment": "staging",
                },
                "threat_model": {
                    "name": "Quick Test",
                    "description": "Test scan",
                    "categories": ["initial_access"],
                    "attack_vectors": ["sql_injection"],
                    "compliance_frameworks": ["soc2"],
                    "priority": 5,
                },
                "scan_mode": "passive",
                "timeout_seconds": 30,
                "stop_on_critical": False,
                "include_proof_of_concept": False,
                "tenant_id": "cancel-test",
                "organization_id": "test-org",
                "tags": ["cancel-test"],
            },
        )
        assert create_response.status_code == 201
        scan_id = create_response.json()["scan_id"]

        # Now try to cancel it - even if completed, this tests the endpoint path
        cancel_response = client.post(
            f"/api/v1/micro-pentest/enterprise/scan/{scan_id}/cancel"
        )
        # The scan may already be completed, so we accept either 200 or 404
        assert cancel_response.status_code in [200, 404]

    def test_scan_with_all_compliance_frameworks(self, client):
        """Test scan with all compliance frameworks including else branch (covers line 583)."""
        # Use all compliance frameworks to hit the else branch for any not explicitly handled
        response = client.post(
            "/api/v1/micro-pentest/enterprise/scan",
            json={
                "name": "Full Compliance Scan",
                "attack_surface": {
                    "name": "Test API",
                    "target_url": "https://api.example.com",
                    "target_type": "api",
                    "endpoints": ["/api/v1/data"],
                    "authentication_required": True,
                    "authentication_type": "jwt",
                    "technologies": ["python", "fastapi"],
                    "environment": "production",
                },
                "threat_model": {
                    "name": "Full Compliance Test",
                    "description": "Test all compliance frameworks",
                    "categories": ["initial_access", "credential_access"],
                    "attack_vectors": ["sql_injection", "xss"],
                    "compliance_frameworks": [
                        "soc2",
                        "iso27001",
                        "pci_dss",
                        "hipaa",
                        "gdpr",
                        "nist_800_53",
                        "cis",
                        "owasp_top_10",
                    ],
                    "priority": 10,
                },
                "scan_mode": "active",
                "timeout_seconds": 60,
                "stop_on_critical": False,
                "include_proof_of_concept": True,
                "tenant_id": "compliance-test",
                "organization_id": "test-org",
                "tags": ["compliance"],
            },
        )
        assert response.status_code == 201
        data = response.json()
        assert "compliance_status" in data
        # Verify all frameworks are in compliance status
        compliance = data["compliance_status"]
        assert len(compliance) == 8


class TestMicroPentestEngineIntegration:
    """Integration tests for MicroPentestEngine class via API."""

    def test_full_scan_workflow(self, client):
        """Test a complete scan workflow: create, get result, list."""
        # Create a scan
        create_response = client.post(
            "/api/v1/micro-pentest/enterprise/scan",
            json={
                "name": "Integration Test Scan",
                "attack_surface": {
                    "name": "Test Service",
                    "target_url": "https://test.example.com",
                    "target_type": "web",
                    "endpoints": ["/login", "/api/data"],
                    "authentication_required": True,
                    "authentication_type": "oauth2",
                    "technologies": ["nodejs", "react", "postgresql"],
                    "environment": "production",
                },
                "threat_model": {
                    "name": "Full Security Assessment",
                    "description": "Comprehensive security testing",
                    "categories": [
                        "initial_access",
                        "execution",
                        "credential_access",
                        "lateral_movement",
                    ],
                    "attack_vectors": [
                        "sql_injection",
                        "xss",
                        "csrf",
                        "ssrf",
                        "authentication_bypass",
                    ],
                    "compliance_frameworks": [
                        "soc2",
                        "pci_dss",
                        "hipaa",
                        "gdpr",
                        "owasp_top_10",
                    ],
                    "priority": 10,
                },
                "scan_mode": "aggressive",
                "timeout_seconds": 120,
                "stop_on_critical": False,
                "include_proof_of_concept": True,
                "tenant_id": "integration-test",
                "organization_id": "test-org",
                "tags": ["integration", "full-test"],
            },
        )
        assert create_response.status_code == 201
        scan_data = create_response.json()
        scan_id = scan_data["scan_id"]

        # Get the scan result
        get_response = client.get(f"/api/v1/micro-pentest/enterprise/scan/{scan_id}")
        assert get_response.status_code == 200
        result_data = get_response.json()
        assert result_data["scan_id"] == scan_id
        assert "findings" in result_data
        assert "compliance_status" in result_data

        # List scans and verify our scan is there
        list_response = client.get(
            "/api/v1/micro-pentest/enterprise/scans",
            params={"tenant_id": "integration-test"},
        )
        assert list_response.status_code == 200
        list_data = list_response.json()
        assert list_data["total"] >= 1

        # Check audit logs
        logs_response = client.get(
            "/api/v1/micro-pentest/enterprise/audit-logs",
            params={"tenant_id": "integration-test"},
        )
        assert logs_response.status_code == 200
        logs_data = logs_response.json()
        assert logs_data["total"] >= 1
