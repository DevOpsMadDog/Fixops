"""Tests for micro penetration test CLI commands."""
import argparse
import json
from unittest.mock import AsyncMock, patch

from core.cli import _handle_micro_pentest, build_parser
from core.micro_pentest import MicroPentestResult, MicroPentestStatus


class TestMicroPentestCLIRun:
    """Tests for micro-pentest run command."""

    def test_run_json_format_success(self, capsys, monkeypatch):
        """Test run command with JSON format and successful result."""
        mock_result = MicroPentestResult(
            status="started",
            flow_id=12345,
            message="Micro penetration test started for 1 CVEs",
        )

        with patch(
            "core.micro_pentest.run_micro_pentest",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            args = argparse.Namespace(
                micro_command="run",
                cve_ids="CVE-2024-1234",
                target_urls="http://example.com",
                context=None,
                format="json",
            )
            result = _handle_micro_pentest(args)

        assert result == 0
        captured = capsys.readouterr()
        output = json.loads(captured.out)
        assert output["flow_id"] == 12345
        assert output["status"] == "started"

    def test_run_text_format_success(self, capsys, monkeypatch):
        """Test run command with text format and successful result."""
        mock_result = MicroPentestResult(
            status="started",
            flow_id=12345,
            message="Micro penetration test started for 1 CVEs",
        )

        with patch(
            "core.micro_pentest.run_micro_pentest",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            args = argparse.Namespace(
                micro_command="run",
                cve_ids="CVE-2024-1234",
                target_urls="http://example.com",
                context=None,
                format="text",
            )
            result = _handle_micro_pentest(args)

        assert result == 0
        captured = capsys.readouterr()
        assert "Started micro pentest flow: 12345" in captured.out
        assert "Status: started" in captured.out

    def test_run_text_format_failure(self, capsys, monkeypatch):
        """Test run command with text format and failed result."""
        mock_result = MicroPentestResult(
            status="error",
            flow_id=None,
            message="PentAGI service unavailable",
        )

        with patch(
            "core.micro_pentest.run_micro_pentest",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            args = argparse.Namespace(
                micro_command="run",
                cve_ids="CVE-2024-1234",
                target_urls="http://example.com",
                context=None,
                format="text",
            )
            result = _handle_micro_pentest(args)

        assert result == 1
        captured = capsys.readouterr()
        assert "Failed to start micro pentest" in captured.out

    def test_run_with_context(self, capsys, monkeypatch):
        """Test run command with context."""
        mock_result = MicroPentestResult(
            status="started",
            flow_id=99999,
            message="Test started",
        )

        with patch(
            "core.micro_pentest.run_micro_pentest",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            args = argparse.Namespace(
                micro_command="run",
                cve_ids="CVE-2024-1234,CVE-2024-5678",
                target_urls="http://example.com,http://test.com",
                context="staging environment",
                format="json",
            )
            result = _handle_micro_pentest(args)

        assert result == 0

    def test_run_multiple_cves_and_urls(self, capsys, monkeypatch):
        """Test run command with multiple CVEs and URLs."""
        mock_result = MicroPentestResult(
            status="started",
            flow_id=11111,
            message="Test started",
        )

        with patch(
            "core.micro_pentest.run_micro_pentest",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            args = argparse.Namespace(
                micro_command="run",
                cve_ids="CVE-2024-1234, CVE-2024-5678, CVE-2024-9999",
                target_urls="http://example.com, http://test.com",
                context=None,
                format="text",
            )
            result = _handle_micro_pentest(args)

        assert result == 0


class TestMicroPentestCLIStatus:
    """Tests for micro-pentest status command."""

    def test_status_json_format_success(self, capsys, monkeypatch):
        """Test status command with JSON format and successful result."""
        mock_status = MicroPentestStatus(
            flow_id=123,
            status="running",
            progress=50,
            tasks=[{"id": 1, "name": "scan"}],
        )

        with patch(
            "core.micro_pentest.get_micro_pentest_status",
            new_callable=AsyncMock,
            return_value=mock_status,
        ):
            args = argparse.Namespace(
                micro_command="status",
                flow_id=123,
                format="json",
            )
            result = _handle_micro_pentest(args)

        assert result == 0
        captured = capsys.readouterr()
        output = json.loads(captured.out)
        assert output["flow_id"] == 123
        assert output["status"] == "running"
        assert output["progress"] == 50

    def test_status_text_format_success(self, capsys, monkeypatch):
        """Test status command with text format and successful result."""
        mock_status = MicroPentestStatus(
            flow_id=123,
            status="running",
            progress=50,
            tasks=[{"id": 1, "name": "scan"}],
        )

        with patch(
            "core.micro_pentest.get_micro_pentest_status",
            new_callable=AsyncMock,
            return_value=mock_status,
        ):
            args = argparse.Namespace(
                micro_command="status",
                flow_id=123,
                format="text",
            )
            result = _handle_micro_pentest(args)

        assert result == 0
        captured = capsys.readouterr()
        assert "Flow ID: 123" in captured.out
        assert "Status: running" in captured.out
        assert "Progress: 50%" in captured.out
        assert "Tasks: 1" in captured.out

    def test_status_text_format_no_tasks(self, capsys, monkeypatch):
        """Test status command with text format and no tasks."""
        mock_status = MicroPentestStatus(
            flow_id=123,
            status="pending",
            progress=0,
            tasks=[],
        )

        with patch(
            "core.micro_pentest.get_micro_pentest_status",
            new_callable=AsyncMock,
            return_value=mock_status,
        ):
            args = argparse.Namespace(
                micro_command="status",
                flow_id=123,
                format="text",
            )
            result = _handle_micro_pentest(args)

        assert result == 0
        captured = capsys.readouterr()
        assert "Tasks:" not in captured.out

    def test_status_text_format_with_error(self, capsys, monkeypatch):
        """Test status command with text format and error."""
        mock_status = MicroPentestStatus(
            flow_id=999,
            status="error",
            progress=0,
            tasks=[],
            error="Flow not found",
        )

        with patch(
            "core.micro_pentest.get_micro_pentest_status",
            new_callable=AsyncMock,
            return_value=mock_status,
        ):
            args = argparse.Namespace(
                micro_command="status",
                flow_id=999,
                format="text",
            )
            result = _handle_micro_pentest(args)

        assert result == 1
        captured = capsys.readouterr()
        assert "Error: Flow not found" in captured.out


class TestMicroPentestCLIBatch:
    """Tests for micro-pentest batch command."""

    def test_batch_json_format_success(self, capsys, tmp_path, monkeypatch):
        """Test batch command with JSON format and successful result."""
        config_file = tmp_path / "batch_config.json"
        config_file.write_text(
            json.dumps(
                {
                    "tests": [
                        {
                            "cve_ids": ["CVE-2024-1234"],
                            "target_urls": ["http://example.com"],
                        },
                        {
                            "cve_ids": ["CVE-2024-5678"],
                            "target_urls": ["http://test.com"],
                            "context": "staging",
                        },
                    ]
                }
            )
        )

        mock_result = {
            "status": "completed",
            "total": 2,
            "successful": 2,
            "failed": 0,
            "results": [
                {"status": "started", "flow_id": 1},
                {"status": "started", "flow_id": 2},
            ],
        }

        with patch(
            "core.micro_pentest.run_batch_micro_pentests",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            args = argparse.Namespace(
                micro_command="batch",
                config_file=str(config_file),
                format="json",
            )
            result = _handle_micro_pentest(args)

        assert result == 0
        captured = capsys.readouterr()
        output = json.loads(captured.out)
        assert output["status"] == "completed"
        assert output["total"] == 2

    def test_batch_text_format_success(self, capsys, tmp_path, monkeypatch):
        """Test batch command with text format and successful result."""
        config_file = tmp_path / "batch_config.json"
        config_file.write_text(
            json.dumps(
                {
                    "tests": [
                        {
                            "cve_ids": ["CVE-2024-1234"],
                            "target_urls": ["http://example.com"],
                        },
                    ]
                }
            )
        )

        mock_result = {
            "status": "completed",
            "total": 1,
            "successful": 1,
            "failed": 0,
            "results": [
                {"status": "started", "flow_id": 123},
            ],
        }

        with patch(
            "core.micro_pentest.run_batch_micro_pentests",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            args = argparse.Namespace(
                micro_command="batch",
                config_file=str(config_file),
                format="text",
            )
            result = _handle_micro_pentest(args)

        assert result == 0
        captured = capsys.readouterr()
        assert "Batch status: completed" in captured.out
        assert "Total: 1" in captured.out
        assert "Successful: 1" in captured.out
        assert "Failed: 0" in captured.out
        assert "Flow 123: started" in captured.out

    def test_batch_text_format_with_failures(self, capsys, tmp_path, monkeypatch):
        """Test batch command with text format and some failures."""
        config_file = tmp_path / "batch_config.json"
        config_file.write_text(
            json.dumps(
                {
                    "tests": [
                        {
                            "cve_ids": ["CVE-2024-1234"],
                            "target_urls": ["http://example.com"],
                        },
                        {
                            "cve_ids": ["CVE-2024-5678"],
                            "target_urls": ["http://test.com"],
                        },
                    ]
                }
            )
        )

        mock_result = {
            "status": "completed",
            "total": 2,
            "successful": 1,
            "failed": 1,
            "results": [
                {"status": "started", "flow_id": 123},
                {"status": "error", "error": "Connection failed"},
            ],
        }

        with patch(
            "core.micro_pentest.run_batch_micro_pentests",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            args = argparse.Namespace(
                micro_command="batch",
                config_file=str(config_file),
                format="text",
            )
            result = _handle_micro_pentest(args)

        assert result == 0
        captured = capsys.readouterr()
        assert "Failed: 1" in captured.out
        assert "Connection failed" in captured.out

    def test_batch_text_format_with_error(self, capsys, tmp_path, monkeypatch):
        """Test batch command with text format and batch error."""
        config_file = tmp_path / "batch_config.json"
        config_file.write_text(
            json.dumps(
                {
                    "tests": [
                        {
                            "cve_ids": ["CVE-2024-1234"],
                            "target_urls": ["http://example.com"],
                        },
                    ]
                }
            )
        )

        mock_result = {
            "status": "error",
            "total": 0,
            "successful": 0,
            "failed": 0,
            "error": "All tests failed to start",
            "results": [],
        }

        with patch(
            "core.micro_pentest.run_batch_micro_pentests",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            args = argparse.Namespace(
                micro_command="batch",
                config_file=str(config_file),
                format="text",
            )
            result = _handle_micro_pentest(args)

        assert result == 1
        captured = capsys.readouterr()
        assert "Error: All tests failed to start" in captured.out

    def test_batch_empty_tests(self, capsys, tmp_path, monkeypatch):
        """Test batch command with empty tests array."""
        config_file = tmp_path / "batch_config.json"
        config_file.write_text(json.dumps({"tests": []}))

        mock_result = {
            "status": "error",
            "total": 0,
            "successful": 0,
            "failed": 0,
            "error": "At least one test configuration is required",
            "results": [],
        }

        with patch(
            "core.micro_pentest.run_batch_micro_pentests",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            args = argparse.Namespace(
                micro_command="batch",
                config_file=str(config_file),
                format="text",
            )
            result = _handle_micro_pentest(args)

        assert result == 1

    def test_batch_result_with_message_fallback(self, capsys, tmp_path, monkeypatch):
        """Test batch command with result that has message instead of error."""
        config_file = tmp_path / "batch_config.json"
        config_file.write_text(
            json.dumps(
                {
                    "tests": [
                        {
                            "cve_ids": ["CVE-2024-1234"],
                            "target_urls": ["http://example.com"],
                        },
                    ]
                }
            )
        )

        mock_result = {
            "status": "completed",
            "total": 1,
            "successful": 0,
            "failed": 1,
            "results": [
                {"status": "error", "message": "Validation failed"},
            ],
        }

        with patch(
            "core.micro_pentest.run_batch_micro_pentests",
            new_callable=AsyncMock,
            return_value=mock_result,
        ):
            args = argparse.Namespace(
                micro_command="batch",
                config_file=str(config_file),
                format="text",
            )
            result = _handle_micro_pentest(args)

        assert result == 0
        captured = capsys.readouterr()
        assert "Validation failed" in captured.out


class TestMicroPentestCLIBatchFileErrors:
    """Tests for batch command file error handling."""

    def test_batch_file_not_found(self, capsys, monkeypatch):
        """Test batch command with non-existent config file."""
        args = argparse.Namespace(
            micro_command="batch",
            config_file="/nonexistent/path/config.json",
            format="text",
        )
        result = _handle_micro_pentest(args)

        assert result == 1
        captured = capsys.readouterr()
        assert "Config file not found" in captured.err

    def test_batch_invalid_json(self, capsys, tmp_path, monkeypatch):
        """Test batch command with invalid JSON in config file."""
        config_file = tmp_path / "invalid_config.json"
        config_file.write_text("{ invalid json }")

        args = argparse.Namespace(
            micro_command="batch",
            config_file=str(config_file),
            format="text",
        )
        result = _handle_micro_pentest(args)

        assert result == 1
        captured = capsys.readouterr()
        assert "Invalid JSON in config file" in captured.err


class TestMicroPentestCLIUnknownCommand:
    """Tests for unknown micro-pentest command."""

    def test_unknown_command(self, capsys, monkeypatch):
        """Test unknown micro-pentest command."""
        args = argparse.Namespace(
            micro_command="unknown",
        )
        result = _handle_micro_pentest(args)

        assert result == 1
        captured = capsys.readouterr()
        assert "Unknown micro pentest command" in captured.err


class TestMicroPentestCLIParser:
    """Tests for micro-pentest CLI parser integration."""

    def test_parser_run_command(self):
        """Test parser recognizes run command."""
        parser = build_parser()
        args = parser.parse_args(
            [
                "micro-pentest",
                "run",
                "--cve-ids",
                "CVE-2024-1234",
                "--target-urls",
                "http://example.com",
            ]
        )
        assert args.micro_command == "run"
        assert args.cve_ids == "CVE-2024-1234"
        assert args.target_urls == "http://example.com"

    def test_parser_run_command_with_context(self):
        """Test parser recognizes run command with context."""
        parser = build_parser()
        args = parser.parse_args(
            [
                "micro-pentest",
                "run",
                "--cve-ids",
                "CVE-2024-1234",
                "--target-urls",
                "http://example.com",
                "--context",
                "staging environment",
            ]
        )
        assert args.context == "staging environment"

    def test_parser_run_command_with_format(self):
        """Test parser recognizes run command with format."""
        parser = build_parser()
        args = parser.parse_args(
            [
                "micro-pentest",
                "run",
                "--cve-ids",
                "CVE-2024-1234",
                "--target-urls",
                "http://example.com",
                "--format",
                "json",
            ]
        )
        assert args.format == "json"

    def test_parser_status_command(self):
        """Test parser recognizes status command."""
        parser = build_parser()
        args = parser.parse_args(["micro-pentest", "status", "12345"])
        assert args.micro_command == "status"
        assert args.flow_id == 12345  # flow_id is parsed as int

    def test_parser_status_command_with_format(self):
        """Test parser recognizes status command with format."""
        parser = build_parser()
        args = parser.parse_args(
            ["micro-pentest", "status", "12345", "--format", "json"]
        )
        assert args.format == "json"

    def test_parser_batch_command(self):
        """Test parser recognizes batch command."""
        parser = build_parser()
        args = parser.parse_args(["micro-pentest", "batch", "config.json"])
        assert args.micro_command == "batch"
        assert args.config_file == "config.json"

    def test_parser_batch_command_with_format(self):
        """Test parser recognizes batch command with format."""
        parser = build_parser()
        args = parser.parse_args(
            ["micro-pentest", "batch", "config.json", "--format", "json"]
        )
        assert args.format == "json"
